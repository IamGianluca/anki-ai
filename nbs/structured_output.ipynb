{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb09f69-7947-408f-b544-a3d874aaab2c",
   "metadata": {},
   "source": [
    "### Structured output\n",
    "\n",
    "We want to constrain the LLM to output in a predefined JSON format to ensure only one note is generated and contains both front and back. The format per se is not a problem. Llama-3.1-8B-Instruct is already capable of following that instruction. However, the issue we are generally facing is that the model sometimes generates multiple notes and, at times, hallucinates by generating multiple notes that go beyond the original note's scope.\n",
    "\n",
    "`vllm` supports guided output out of the box and uses `outlines` under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbb7e4-bd90-42e9-9afa-80f1b8172ffb",
   "metadata": {},
   "source": [
    "Please run the following command on the terminal to spin up a vLLM server, which we will query in the rest of the notebook.\n",
    "\n",
    "```bash\n",
    "$ vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --max_model_len 4096 --chat-template ./template_llama31.jinja\n",
    "```\n",
    "\n",
    "We might have to wait about 1 minute before the server is up and reachable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a41217b-aa6f-4f32-a9af-3c55fd104ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb87dd54-886d-4b57-9981-4ee88e1de245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33f5a3a-3863-486b-846a-5913838082b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5257fc-a3a2-4630-8f52-f117c8b62a9b",
   "metadata": {},
   "source": [
    "### Completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f69750e-162f-45ba-b711-96179d2a9532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion result:  Paris\n",
      "What is the capital of\n"
     ]
    }
   ],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    prompt=\"What is the capital of France?\",\n",
    "    temperature=0,\n",
    "    max_tokens=7,\n",
    ")\n",
    "print(\"Completion result:\", completion.choices[0].text);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a1aff-d518-495c-a04f-b4df852a883c",
   "metadata": {},
   "source": [
    "### Chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b57ddb8-dee0-4382-8ed7-106dbf6e267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(\"Chat response:\", chat_response.choices[0].message.content);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97841415-3ee4-45c4-b059-07ca9c6d16b8",
   "metadata": {},
   "source": [
    "### Chat API + Guided Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f1f7f1-9562-4ec8-9893-72c866a0301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: Paris\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    extra_body={\n",
    "        \"guided_choice\": [\n",
    "            \"SÃ£o Paulo\",\n",
    "            \"Rome\",\n",
    "            \"New York\",\n",
    "            \"Paris\",\n",
    "            \"Milan\",\n",
    "            \"Los Angeles\",\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "print(\"Chat response:\", chat_response.choices[0].message.content);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6da111-2d9b-4571-b76e-0970b5cd0ac7",
   "metadata": {},
   "source": [
    "### Chat API + Guided JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d1db26-660f-459d-8beb-4a9b3464450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: { \"name\": \"Paris\" }\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    extra_body={\n",
    "        \"guided_json\": {\n",
    "            \"title\": \"City\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"string\"},\n",
    "            },\n",
    "            \"required\": [\"name\"],\n",
    "        }\n",
    "    },\n",
    ")\n",
    "print(\"Chat response:\", chat_response.choices[0].message.content);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920617af-c8f1-4d49-8fcb-ec8739379adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
