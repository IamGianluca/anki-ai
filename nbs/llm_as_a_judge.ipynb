{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfc59c0-44ee-4c92-a592-5c7701887fb9",
   "metadata": {},
   "source": [
    "# LLM as a Judge\n",
    "\n",
    "So far, we have been manually reviewing the LLM editor's outputs. This has been a relatively smooth process, but it is not scalable, as there are many failure cases we would need to keep track of. Investing in building an LLM judge makes sense at this stage. \n",
    "\n",
    "Before deploying an LLM judge, we need to ensure its performance is aligned with that of a human judge. This is critical as we would otherwise risk optimizing the wrong metric.\n",
    "\n",
    "Let's get started by creating a small human-annotated dataset of reviews. This dataset will later be used to evaluate the performance of our LLM judge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a75b2-92ac-45fc-b93e-7e2c3326f0a2",
   "metadata": {},
   "source": [
    "### Create an Eval dataset\n",
    "\n",
    "To ease the process of creating an eval dataset, we built a small utility class, `ReviewApp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2604a72f-363e-4aa8-8f59-531135520961",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7291c877-6479-4973-b5c9-a6f62d6dbbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from json.decoder import JSONDecodeError\n",
    "from typing import cast\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from anki_ai.domain.model import Deck\n",
    "from anki_ai.entrypoints.review_notes_changes import ReviewApp\n",
    "from anki_ai.service_layer.services import (\n",
    "    ChatCompletionsService,\n",
    "    get_chat_completion,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53f6d7d-111d-4b1e-852d-b81f8edc16e1",
   "metadata": {},
   "source": [
    "We have collected annotations for over 200 notes. We will use this dataset to evaluate the model's alignment with our preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387bd2a9-04cb-44f3-b53e-2d1ae92e7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_deck = Deck(\"original\")\n",
    "orig_deck.read_txt(\"../data/Selected Notes v7.txt\")\n",
    "\n",
    "deck = Deck(\"edited\")\n",
    "deck.read_txt(\"../data/new_deck.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9777f93-d89f-4f60-b698-abb5e184052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = ReviewApp(old_deck=orig_deck, new_deck=deck)\n",
    "ra.load(\"../data/eval.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0c191-315e-481a-9aa0-cfe92e427678",
   "metadata": {},
   "source": [
    "### Create a very simple LLM judge\n",
    "\n",
    "Let's create a simple LLM judge, and evaluate its alignment with human preference by measuring how well it does on the eval dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47198333-9083-4c84-82ca-fdf3ccfff28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "The LLM did not comply with the prompt and returned something different from True or False: invalid syntax (<string>, line 3)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "The LLM did not comply with the prompt and returned something different from True or False: invalid syntax (<string>, line 3)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "The LLM did not comply with the prompt and returned something different from True or False: invalid syntax (<string>, line 3)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "The LLM did not comply with the prompt and returned something different from True or False: invalid syntax (<string>, line 3)\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "The LLM did not comply with the prompt and returned something different from True or False: invalid syntax (<string>, line 3)\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: Verdict(is_correct=True)\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: Verdict(is_correct=False)\n",
      "#######################\n",
      "Alignment: 15/20 (75.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V1 = r\"\"\"\n",
    "Your job is to evaluate Anki's notes and classify notes that are not formatted correctly.\n",
    "\n",
    "Requirements:\n",
    "* Only check formatting\n",
    "* Notes are written in hybrid markdown; for instance: the newline character is `<br>,` `<` is `&lt;`, etc.\n",
    "* Preserve images and media on the original note\n",
    "* Use code block: ```<language><br><command><br>```\n",
    "* Use inline code format for short commands: e.g., `iw`, `d`, etc.\n",
    "\n",
    "Provide only a boolean score: False for bad and True for good.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from jinja2 import Template\n",
    "\n",
    "\n",
    "class LLMJudge:\n",
    "    def __init__(\n",
    "        self,\n",
    "        chat: ChatCompletionsService,\n",
    "        system_msg: str,\n",
    "        user_msg_tmpl: str,\n",
    "        model_name: str = \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    ) -> None:\n",
    "        self.chat = chat\n",
    "        self.system_msg = system_msg\n",
    "        self.user_msg_tmpl = Template(user_msg_tmpl)\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def review(self, note) -> bool:\n",
    "        user_msg = self.user_msg_tmpl.render(note=note)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ]\n",
    "        chat_response = self.chat.create(\n",
    "            model=self.model_name,\n",
    "            messages=messages,  # type: ignore\n",
    "            temperature=0,\n",
    "        )\n",
    "        result: str = cast(str, chat_response.choices[0].message.content)\n",
    "        return Verdict(is_correct=eval(result))\n",
    "\n",
    "\n",
    "user_msg_tmpl = \"\"\"Front: {{ note.front }}\n",
    "Back: {{ note.back }}\n",
    "Tags: {{ note.tags }}\n",
    "\"\"\"\n",
    "\n",
    "chat = get_chat_completion()\n",
    "judge = LLMJudge(chat=chat, system_msg=SYSTEM_MSG_V1, user_msg_tmpl=user_msg_tmpl)\n",
    "Verdict = namedtuple(\"Verdict\", [\"is_correct\"])\n",
    "\n",
    "\n",
    "def review_notes(ra, judge):\n",
    "    aligned = 0\n",
    "    tot = 0\n",
    "    for guid, score in ra._ReviewApp__reviews.items():\n",
    "        note = deck.get(guid=guid)[0]\n",
    "        try:\n",
    "            verdict = judge.review(note)\n",
    "            if verdict.is_correct == eval(score):\n",
    "                aligned += 1\n",
    "            tot += 1\n",
    "            print(f\"Ground Truth: {eval(score)}\\nVerdict: {verdict}\")\n",
    "        except SyntaxError as e:\n",
    "            print(\n",
    "                f\"The LLM did not comply with the prompt and returned something different from True or False: {e}\"\n",
    "            )\n",
    "            print(\"#######################\")\n",
    "        else:\n",
    "            print(\"#######################\")\n",
    "    print(f\"Alignment: {aligned}/{tot} ({aligned / tot:.2%})\")\n",
    "\n",
    "\n",
    "review_notes(ra=ra, judge=judge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69ebec-724d-4b22-bd20-f42c9a12c220",
   "metadata": {},
   "source": [
    "This first model is not that bad; however, quite frequently, it does not follow the instructions and returns something other than a boolean. Let's fix that by using structured output and improving performance with some prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae7ac6-d84f-43a5-99d9-a798939737c7",
   "metadata": {},
   "source": [
    "### Improve performance of LLM judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd0d8c-ca82-4573-a82b-46e9996552bf",
   "metadata": {},
   "source": [
    "#### Structured output\n",
    "\n",
    "The LLM judge's performance seems decent, but we should use structured output to make it more manageable and avoid scenarios when the LLM does not follow the instructions properly and returns something other than a boolean. This can happen quite frequently. To address that, let's use structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd89758-9c43-4994-a6e0-5515072a0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' is_correct=True\n",
      "#######################\n",
      "Alignment: 16/25 (64.00%)\n"
     ]
    }
   ],
   "source": [
    "class Review(BaseModel):\n",
    "    guid: str\n",
    "    is_correct: bool\n",
    "\n",
    "\n",
    "class LLMJudgeJSON:\n",
    "    def __init__(\n",
    "        self,\n",
    "        chat: ChatCompletionsService,\n",
    "        system_msg: str,\n",
    "        user_msg_tmpl: str,\n",
    "        model_name: str = \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        review_model=Review,\n",
    "    ) -> None:\n",
    "        self.chat = chat\n",
    "        self.system_msg = system_msg\n",
    "        self.user_msg_tmpl = Template(user_msg_tmpl)\n",
    "        self.model_name = model_name\n",
    "        self.review_model = review_model\n",
    "\n",
    "    def review(self, note) -> bool:\n",
    "        user_msg = self.user_msg_tmpl.render(note=note)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ]\n",
    "        extra_body = {\n",
    "            \"guided_json\": self.review_model.model_json_schema(),\n",
    "            \"guided_whitespace_pattern\": r\"[\\n\\t ]*\",\n",
    "        }\n",
    "\n",
    "        chat_response = chat.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,  # type: ignore\n",
    "            temperature=0,\n",
    "            extra_body=extra_body,\n",
    "        )\n",
    "        content_str: str = cast(str, chat_response.choices[0].message.content)\n",
    "        try:\n",
    "            content_dict = json.loads(content_str)\n",
    "            content_dict[\"guid\"] = note.guid\n",
    "            updated_content_str = json.dumps(content_dict)\n",
    "            result = self.review_model.model_validate_json(updated_content_str)\n",
    "            return result\n",
    "        except JSONDecodeError as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat, system_msg=SYSTEM_MSG_V1, user_msg_tmpl=user_msg_tmpl\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aaf054-fda7-458e-b97b-e51592169880",
   "metadata": {},
   "source": [
    "#### Few-shot prompting\n",
    "\n",
    "Some of the answers are incorrect. Let's try to pass a few examples to the LLM judge to see if we can improve on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b383fbd-c077-46e4-9c2d-b2412a788d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' is_correct=False\n",
      "#######################\n",
      "Alignment: 16/25 (64.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V2 = r\"\"\"\n",
    "Your job is to evaluate Anki notes, and classify notes that are not formatted correctly.\n",
    "\n",
    "Requirements:\n",
    "* Only check formatting\n",
    "* Notes should be in HTML format; for instance: newline should \"<br>\", \"<\" should be \"&lt;\", etc.\n",
    "* Preserve images and media on the original note\n",
    "* Use code block: ```<language><br><command><br>```\n",
    "* Use inline code format for very short commands: `iw`, `d`, etc.\n",
    "\n",
    "Examples of good notes:\n",
    "\n",
    "Example 1:\n",
    "\n",
    "    Front: Create soft link\n",
    "    Back:  ```bash<br>$ ln -s <file> <link><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Example 2:\n",
    "\n",
    "    Front: Zip destination option\n",
    "    Back:  ```bash<br>$ unzip <file> -d <path><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Example 3:\n",
    "\n",
    "    Front: Extract zip files\n",
    "    Back:  ```bash<br>$ unzip <file><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Example 4:\n",
    "\n",
    "    Front: List directory content\n",
    "    Back:  ```bash<br>$ ls <path><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Examples of bad notes: \n",
    "\n",
    "Example 1:\n",
    "\n",
    "    Front: Return to previous directory\n",
    "    Back:  ```bash $ cd -```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "    Reasoning: Missing newlines (<br> tags) in code block\n",
    "\n",
    "Example 2: \n",
    "\n",
    "    Front: Remove delimiters\n",
    "    Back:  ```ds <delimiter>```\n",
    "    Tags:  ['nvim']\n",
    "\n",
    "    Reasoning: Using triple backtick quotes without specifying the language and adding newlines (<br> tag) in code block\n",
    "\n",
    "Example 3: \n",
    "\n",
    "    Front: Change Anki delimiters\n",
    "    Back:  ```\\\n",
    "    Tags:  ['nvim']\n",
    "    \n",
    "    Reasoning: Mentioning the command is an Anki command when, in fact, it's a nvim command\n",
    "\n",
    "Example 4: \n",
    "\n",
    "    Front: Text object for a sentence\n",
    "    Back:  ```\\\n",
    "    Tags:  ['nvim']\n",
    "    \n",
    "    Reasoning: Missing command and not closing code block\n",
    "\"\"\"\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat, system_msg=SYSTEM_MSG_V2, user_msg_tmpl=user_msg_tmpl\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c7cea-f500-45a5-9bf1-0c47e5b5e206",
   "metadata": {},
   "source": [
    "This result is also surprising. We would have expected a few examples to help the model understand the expected formatting for these notes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cb930-60d6-4226-abf5-4efe19091b87",
   "metadata": {},
   "source": [
    "#### Reasoning\n",
    "\n",
    "One thing we would expect to improve performance is to ask the LLM judge to provide some reasoning for its decision before submitting a verdict. Let's see if that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84716b2d-34d7-4a83-8a83-cafb5669535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original code, and wraps the code in a code block.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' reasoning='The note is properly formatted as it uses the required tags and does not contain any code, math, or media that would require special formatting.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the image, and uses code blocks for commands.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' reasoning=\"This note is properly formatted as it uses the required hybrid markdown format, preserves the original note's formatting, and uses the correct formatting for code and math.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' reasoning='The note is properly formatted as it uses the required fields: Front, Back, and Tags. However, it lacks the use of hybrid markdown format, which is a requirement for proper formatting.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original note, and uses code blocks for commands.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original text, and does not contain any code or math blocks. The tags are also properly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' reasoning='This note does not contain any formatting issues. It does not contain any code, math, or media that would require special formatting. The tags are properly formatted as a list.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' reasoning='The number of columns in the first matrix must be equal to the number of rows in the second matrix' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the image, and wraps the code in a code block. The tags are also properly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' reasoning='The note is properly formatted as it uses the required format and does not contain any code, math, or media that would require special formatting. However, the note could be improved by adding a description or explanation of the concept of adversarial validation.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the image (there is no image in this note), and uses a LaTeX block for the math equation. The formula is also correctly displayed without double backslashes.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' reasoning=\"The note is properly formatted. It uses hybrid markdown format, preserves the original note's formatting, and wraps the code in a code block.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the original note, and uses code blocks for commands. However, it does not wrap the short command in an inline code block.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' reasoning='The note is properly formatted. It uses a simple text format, which is acceptable for Anki notes. The front and back of the note are clear and concise, and the tags are properly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the image/media, and uses code blocks for commands. However, the math equation is not wrapped in a LaTeX block. The correct format should be: $[0,5) == 0, 1, 2, 3, 4$' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the image (although there is no image in this note), and wraps the code in a code block with the correct language and syntax.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' reasoning='The note is properly formatted as it uses the required tags and does not contain any code, math, or media that would require special formatting. However, the note is very short and does not contain any special formatting. It is still a valid note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' reasoning='The note is missing the required formatting. It does not use hybrid markdown format, nor does it wrap the tags in a code block. It also does not wrap the short command in an inline code block.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' reasoning='The note uses LaTeX format for the math equation, but it incorrectly uses double backslashes, \\\\, in the LaTeX block. This will not be correctly displayed in Anki.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' reasoning=\"The note is using inline code for the command `expect()` and `Ok` value, and it's also using the correct markdown format for the front and back of the note. The tags are also properly formatted.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' reasoning='The note is missing the front and back fields. The front field should contain the PCIe 5.0 bidirectional bandwidth in a hybrid markdown format, and the back field should contain the calculation in a hybrid markdown format. The tags are also missing the square brackets around the list of tags.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' reasoning='The note is properly formatted as it uses the required tags and does not contain any formatting issues.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' reasoning='The note is too short and lacks any additional information. It should include a definition, formula, or example to make it more useful for learning.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' reasoning=\"Avoid God Class is a design principle that suggests that a class should not have too many responsibilities. This note is properly formatted as it uses a simple text format, which is suitable for Anki notes. However, it would be better to use a hybrid markdown format for better readability. Here is the corrected version: <br> Front: Avoid God Class <br> Back: 1. Better infrastructure abstractions <br> 2. Less pure approach <br> 3. Split Application layer into multiple classes <br> Tags: ['software-testing'] <br> <br> True/False: False <br> <br> Corrected Note: <br> Front: `Avoid God Class` <br> Back: 1. Better infrastructure abstractions <br> 2. Less pure approach <br> 3. Split Application layer into multiple classes <br> Tags: ['software-testing'] <br> <br> } <br> \" is_correct=False\n",
      "#######################\n",
      "Alignment: 15/25 (60.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V3 = r\"\"\"\n",
    "Your job is to evaluate the formatting of Anki note.\n",
    "\n",
    "Properly formatted notes should:\n",
    "* Use hybrid markdown format. For instance, use \"<br>\" to signal a new line, \"&lt;\" for \"<\" symbol, etc.\n",
    "* Preserve images and media on the original note\n",
    "* Wrap code in a code block: ```<language><br><command><br>```\n",
    "* Wrap math in a LaTeX block: $ <math equation> $. Also, ensure that we do not use double backslashes, \\\\, in a LaTeX block, as that won't be correctly displayed\n",
    "* Wrap short commands in an inline code block: `iw`, `d`, etc.\n",
    "\n",
    "Provide concise reasoning for your answer and a True/False answer, where True means the note is formatted correctly and False means the note is not properly formatted.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Review2(BaseModel):\n",
    "    guid: str\n",
    "    reasoning: str\n",
    "    is_correct: bool\n",
    "\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat,\n",
    "    system_msg=SYSTEM_MSG_V3,\n",
    "    user_msg_tmpl=user_msg_tmpl,\n",
    "    review_model=Review2,\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345368e-26f6-4e5c-9e3e-fd2c08d7ba05",
   "metadata": {},
   "source": [
    "#### Provide original notes\n",
    "\n",
    "The LLM judge made some mistakes due to not having access to the original note. For instance, the LLM judge would not know if the LLM editor removed an image or block of code present in the original note. Let's try to address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca9f553-afb1-4cf5-8ef8-a93e7ba53571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' reasoning='The improved note uses hybrid markdown format for the code block, but it should be wrapped in a code block with a language specified, such as `bash`. The link should be on a new line.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' reasoning='The improved note is not properly formatted because it does not use the hybrid markdown format. It should be wrapped in a code block or use inline code for the command.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' reasoning='The improved note is not properly formatted because it does not use the hybrid markdown format. The note should be wrapped in a code block or use inline code for commands.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' reasoning='The improved note is not properly formatted because it does not use the hybrid markdown format. The note should be wrapped in a code block to preserve the formatting and the tags should be separated by commas.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' reasoning='The note does not require special formatting as it only contains a single sentence without code or math equations. The note is properly formatted as it does not need to use hybrid markdown format.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' reasoning='The improved note is properly formatted as it uses hybrid markdown format and preserves the original content. The code is wrapped in a code block and the tags are properly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' reasoning='The note is properly formatted as it does not require special formatting, and it does not include code or math equations.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' reasoning='The improved note is not properly formatted because it does not use hybrid markdown format. The note does not include code or math equations, but it still lacks proper formatting for a sentence that is not a single line of text.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' reasoning='The original note is not provided, but the improved note is properly formatted as it does not require any special formatting. The note is a simple sentence that does not include code or math equations.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' reasoning='The note is properly formatted as it uses a simple format suitable for a one-sentence note without code or math equations. The use of curly brackets to enclose the note is also a good practice.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' reasoning='The note is a simple sentence that does not include code or math equations, so it does not require special formatting. The note is already in a simple and concise format, so no further improvement is needed.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' reasoning=\"The improved note uses a LaTeX block to display the mathematical equation, which is correct. However, it does not use the hybrid markdown format for the front of the note, which is not necessary in this case since it's a single sentence without code or math equations.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' reasoning='The improved note uses the hybrid markdown format for the code block, but it should be wrapped in a code block with the language specified, in this case, bash. The improved note also does not include the language in the code block.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' reasoning='The note does not require special formatting as it is a single sentence without code or math equations. However, it would be beneficial to use markdown to make the text more readable.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' reasoning='The note is not properly formatted. It does not use the hybrid markdown format and does not wrap the tags in square brackets.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' reasoning='The improved note is not properly formatted because it does not use hybrid markdown format. The note does not require special formatting since it is a single sentence without code or math equations, but it could be improved by adding a space between the sentence and the example.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' reasoning='The improved note uses hybrid markdown format for the code block, but it should be wrapped in a code block with the language specified, and the file name should be on a new line. The file name should be wrapped in a code block as well.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' reasoning='The note is a simple sentence that does not require special formatting. The note is properly formatted as it does not include code, math equations, or images.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' reasoning='The note is a simple sentence that does not include code or math equations, so it does not require special formatting. The note is properly formatted as it is a simple sentence without any special formatting needed.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' reasoning='The improved note is not properly formatted because it uses double backslashes, \\\\, in the LaTeX block. This will not be correctly displayed in Anki.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' reasoning='The improved note is properly formatted as it uses a code block for the code and does not require any special formatting for the text. The note also preserves the original tags.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' reasoning='The improved note is not properly formatted because it does not use hybrid markdown format. The note should use `<br>` to signal a new line and `&nbsp;` to signal a non-breaking space if necessary.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' reasoning='The note does not require special formatting as it only contains a single sentence without code or math equations. However, it would be beneficial to add tags to the front for better organization.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' reasoning=\"The improved note is not properly formatted because it does not use the hybrid markdown format. The note should have at least a brief description of Euler's number.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' reasoning='The improved note is not properly formatted because it does not use the hybrid markdown format. The note should be formatted with a clear separation between the front and back sides, and the back side should be formatted with a list or other clear structure.' is_correct=False\n",
      "#######################\n",
      "Alignment: 13/25 (52.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V4 = r\"\"\"\n",
    "The user will share two Anki notes: the original and improved versions. The improved version should be factually the same as the original note but more concise and might have a slightly different format.\n",
    "\n",
    "Your job is to evaluate the formatting of the improved version. Properly formatted notes should:\n",
    "* Use hybrid markdown format. For instance, when relevant, use `<br>` to signal a new line, `&nbsp;` to signal a non-breaking space, `&lt;` for `<` symbol, etc. Cards with just one sentence that do not include code or math equations do not require special formatting\n",
    "* Preserve images and media present on the original note\n",
    "* Code should be wrapped in a code block: ```<language><br><command><br>```. One line command should use an inline code block: `iw`, `d`, `:copen`, etc.\n",
    "* Mathematical equations should be wrapped in a LaTeX block: $ <math equation> $. Also, ensure that we do not use double backslashes, \\\\, in a LaTeX block, as that won't be correctly displayed\n",
    "\n",
    "Provide concise reasoning (no more than two sentences) for your answer and a True/False answer, where True means the improved note is formatted correctly and False means the improved note is not properly formatted.\n",
    "\"\"\"\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat,\n",
    "    system_msg=SYSTEM_MSG_V4,\n",
    "    user_msg_tmpl=user_msg_tmpl,\n",
    "    review_model=Review2,\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280a996d-da73-4f5e-bebe-40df05ddba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' reasoning='The improved note is properly formatted. It uses hybrid markdown format, preserves the original command, and wraps the code in a code block.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' reasoning='The note is properly formatted. It uses a simple sentence and does not require any special formatting. The tags are also properly formatted as a list.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' reasoning='The improved note is not properly formatted. It does not use the hybrid markdown format. The front and back cards are just one sentence and do not include code or math equations, so they do not require special formatting, but they should be in a proper markdown format. For instance, they should be in a single line, and the text should be separated by a space or a period. The improved note is missing this.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' reasoning='The note is properly formatted as it does not require special formatting. However, it would be beneficial to add the tags in a list format, e.g., [\"dl\"]' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' reasoning='The note is very simple and does not require any special formatting. It is already in a simple sentence format and does not include code or math equations.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' reasoning='The improved note is properly formatted. The front and back cards use a simple sentence format, which does not require special formatting. The tags are enclosed in square brackets, which is the correct format for Anki tags.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' reasoning='The note is properly formatted. It uses a simple sentence and does not include code or math equations, so it does not require special formatting. The tags are also properly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' reasoning='The original note is provided as a reference to ensure we are preserving the intention of the note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' reasoning='The note is properly formatted as it does not require any special formatting. It is a single sentence without code or math equations.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' reasoning='The improved note is not provided, so I will assume it is the following: ' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' reasoning='The note is properly formatted. It uses a simple sentence and does not require special formatting. The tags are also properly formatted as a list.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' reasoning='The original note is provided only as a reference to ensure we are preserving the intention of the note and any media/code example.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' reasoning='The improved note uses hybrid markdown format, preserves the original code, and uses a code block for the bash command. The use of `<br>` is correct for a multi-line code block. The tags are also properly formatted as a list.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' reasoning='The note is properly formatted. It uses a simple sentence without any code or math equations, so no special formatting is required.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' reasoning='reference note' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' reasoning=\"The improved note is properly formatted. It uses hybrid markdown format, preserves the original note's intention, and does not require special formatting for the text. The tags are also properly formatted.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' reasoning=\"The improved note uses hybrid markdown format for the code block, but it is missing the language specification. It should be `bash` instead of just `bash<br>`. Also, the back card should be properly formatted to include the original note's intention, which is to show the output of the command. The improved note is missing the output of the command.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' reasoning='The note is properly formatted as it does not require any special formatting. It is a single sentence without code or math equations.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' reasoning='The note is properly formatted. It uses a simple sentence and does not include code or math equations, so it does not require special formatting. The tags are also properly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' reasoning='The original note is provided as a reference to ensure we are preserving the intention of the note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' reasoning='The improved note is not properly formatted. The code should be wrapped in a code block: `expect()`<br>Ok`<br>`. One line command should use an inline code block: `expect()`' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' reasoning='The improved note is properly formatted. It uses a simple sentence and does not require special formatting. The tags are also properly formatted as a list.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' reasoning='The note does not contain any code, math equations, or media, so it does not require special formatting. The note is already in a simple, one-sentence format, which is suitable for a note without code or math.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' reasoning=\"The improved note is missing the front and back content. It should be a concise version of the original note, but it does not provide any information about Euler's number. The tags are properly formatted as a list.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' reasoning='The note is a simple text note and does not require special formatting. However, it is good practice to use the hybrid markdown format for clarity and readability. In this case, the note could be formatted as follows: <br><br>1. Better infrastructure abstractions <br>2. Less pure approach <br>3. Split Application layer into multiple classes' is_correct=True\n",
      "#######################\n",
      "Alignment: 15/25 (60.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V5 = r\"\"\"\n",
    "The user will share two Anki notes: the original and improved versions. Here is an example of the input:\n",
    "\n",
    "Original note:\n",
    "Front: <original front>\n",
    "Back: <original back>\n",
    "Tags: <original tags>\n",
    "\n",
    "Improved note:\n",
    "Front: <improved front>\n",
    "Back: <improved back>\n",
    "Tags: <improved tags>\n",
    "\n",
    "The improved version should be factually the same as the original note but more concise and might have a slightly different format.\n",
    "\n",
    "Evaluate the formatting of the improved note, both front and back cards. Properly formatted notes should:\n",
    "* Use hybrid markdown format. For instance, when relevant, use `<br>` to signal a new line, `&lt;` for `<` symbol, etc. Cards with just one sentence that do not include code or math equations do not require special formatting\n",
    "* Preserve images and media present on the original note\n",
    "* Code should be wrapped in a code block: ```<language><br><command><br>```. One line command should use an inline code block: `iw`, `d`, `:copen`, etc.\n",
    "* Mathematical equations should be wrapped in a LaTeX block: $ <math equation> $. Also, ensure that we do not use double backslashes, \\\\, in a LaTeX block, as that won't be correctly displayed\n",
    "\n",
    "The original note is provided only as a reference to ensure we are preserving the intention of the note and any media/code example.\n",
    "\n",
    "Provide concise reasoning for your answer and a True/False answer, where True means the improved note is formatted correctly and False means the improved note is not properly formatted.\n",
    "\"\"\"\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat,\n",
    "    system_msg=SYSTEM_MSG_V5,\n",
    "    user_msg_tmpl=user_msg_tmpl,\n",
    "    review_model=Review2,\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabe5b6-3201-431a-8e02-f309b101125b",
   "metadata": {},
   "source": [
    "It seems the LLM judge is often confusing the old and new notes. Let's try to refactor the prompt (thank you Claude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2631d493-4748-4c05-aed6-cd8bd3e0c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' reasoning=\"The improved note correctly uses hybrid markdown, preserves images, and properly formats code. However, the improved note could be more concise by removing the unnecessary line break and using a more specific language specification for the code block. The original note's intent and key information are maintained.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' reasoning='The original note is a simple definition, and the improved note maintains the same content and tags. However, it does not utilize the hybrid markdown format as it does not require any special formatting. The note is concise and effectively conveys the definition of an integer.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' reasoning='The improved note is a simple sentence and does not require special formatting. It uses the correct markdown for the front side of the note. However, the back side could be improved by using a code block for the definition, but it is not necessary in this case. The tags are correctly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' reasoning='The improved note maintains the original intent and uses a clear, concise format. However, it lacks a specific percentage increase in the LR, which could be added for clarity. The use of <br> for line breaks is also unnecessary in this case, as the content is a single sentence. The tags are correctly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' reasoning='The improved note is a simple note and does not require any special formatting. It uses the correct markdown for the front and back sides, and the tags are properly formatted as a list. However, it does not include any images, code, or mathematical equations, so it does not require any special handling for those elements.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' reasoning='The improved note maintains the original content and uses the correct markdown format for the front side. However, it does not follow the specified format for tags.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' reasoning='The improved note is a simple text-based note and does not require any special formatting. It uses the correct markdown for the front and back sides, and the tags are properly formatted. However, it does not follow the exact format specified in the evaluation criteria, as it does not use <br> for line breaks and does not specify the language for the code block. Nevertheless, it is a correctly formatted note in the context of Anki.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' reasoning=\"The improved note maintains the original content and uses a simple format suitable for a single-sentence note. However, it could benefit from a more descriptive front side, potentially including the key takeaway or a brief explanation. The use of markdown is not necessary in this case, but it's still a good practice to include it for consistency. The tags are correctly preserved.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' reasoning='The improved note correctly uses hybrid markdown, preserves the original intent, and properly formats the content. The use of italics for emphasis is a good improvement.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' reasoning='The improved note is missing. Please provide the improved note for evaluation.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' reasoning=\"The improved note maintains the original intent and key information. However, it lacks proper formatting. The improved note should utilize hybrid markdown format, and the tags should be enclosed in square brackets. The original note's content is concise and does not require special formatting, but it would benefit from proper formatting for future reference.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' reasoning=\"The improved note correctly uses hybrid markdown, preserves the equation, and properly formats it as a LaTeX block. The original note's intent and key information are maintained.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' reasoning=\"The improved note correctly uses hybrid markdown, preserves images, and properly formats code. However, the improved note does not preserve the original note's intent and key information as it only provides a command and does not explain what changing the directory means or what it is used for. It also does not handle line breaks correctly as it uses <br> tags which are not necessary in this case.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' reasoning='The improved note maintains the original content and uses a simple, clear format. It does not require any special formatting for code or math, as the content is straightforward. The use of <br> for line breaks is appropriate for this type of content.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' reasoning=\"The improved note is a simple text-based note and does not require any special formatting. It maintains the original note's intent and key information. However, it would be beneficial to add a brief description of the recipe to the front side for better understanding.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' reasoning='The improved note maintains the original intent and formatting. It uses a simple markdown format for the front and back sides, which is suitable for this type of note. The use of == to represent the interval is a good way to illustrate the concept. However, it would be beneficial to include the definition of a closed interval in the back side for better understanding. The tags are correctly formatted.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' reasoning=\"The improved note correctly uses hybrid markdown, preserves images, and properly formats code. However, the improved note does not preserve the original note's intent as it suggests running the command with a specific file, which is not present in the original note. The original note only shows the command to run git diff origin/main. The improved note should be more concise and not suggest running the command with a specific file.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' reasoning='The improved note is missing the reasoning section, however, the improved note is correctly formatted. It uses hybrid markdown, preserves the original intent, and does not have any formatting issues.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' reasoning='The improved note maintains the original content and uses a simple format suitable for a single-sentence note. However, it could benefit from a more descriptive front side, potentially including a brief explanation or a question to encourage deeper understanding. The use of markdown is not necessary in this case, but it does not cause any issues. The tags are correctly preserved.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' reasoning=\"The original note is a simple equation, so it doesn't require any special formatting. The improved note maintains the original content and uses LaTeX to format the equation correctly. However, it's worth noting that the improved note could be more concise by removing the unnecessary LaTeX wrapper around the fraction.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' reasoning='The improved note is correctly formatted. It uses hybrid markdown and properly handles the code example. The front side clearly explains the purpose of `expect()` with an `Ok` value, and the back side provides a concise and accurate description of how to handle the return value.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' reasoning='The improved note is a simple statement and does not require special formatting. However, it could be improved by adding a brief explanation or context to the back side. The note is well-formatted and uses the correct tags.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' reasoning=\"The improved note is a simple sentence and does not require special formatting. However, it is missing the necessary tags to preserve the original note's intent and key information. The original note had tags ['ml', 'ltr', 'recsys', 'retrieval'] which are crucial for organization and retrieval. The improved note is missing these tags.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' reasoning=\"The original note is very basic and does not contain any complex formatting. However, it does not follow the required format for Anki notes. The improved note should be more descriptive and follow the required format. In this case, the improved note is still very basic and does not follow the required format. It should be more descriptive and include more information about Euler's number.\" is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' reasoning='The improved note maintains the original content and uses a simple format suitable for a single-sentence note. However, it could benefit from a brief explanation or example to support the key points listed in the back. The tags are correctly formatted as a list.' is_correct=True\n",
      "#######################\n",
      "Alignment: 15/25 (60.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V6 = r\"\"\"You will be presented with two versions of an Anki note: the original and an improved version. Your task is to evaluate the formatting of the improved note, ensuring it maintains the original's factual content while potentially being more concise or having a slightly different format.\n",
    "\n",
    "## Input Format\n",
    "\n",
    "The input will be structured as follows:\n",
    "\n",
    "```\n",
    "Original note:\n",
    "Front: <original front content>\n",
    "Back: <original back content>\n",
    "Tags: <original tags>\n",
    "\n",
    "Improved note:\n",
    "Front: <improved front content>\n",
    "Back: <improved back content>\n",
    "Tags: <improved tags>\n",
    "```\n",
    "\n",
    "## Evaluation Criteria\n",
    "\n",
    "Assess the improved note's formatting for both front and back sides. A properly formatted note should:\n",
    "\n",
    "1. Utilize hybrid markdown format:\n",
    "   - Use `<br>` for line breaks when necessary\n",
    "   - Use `&lt;` for `<` symbol, `&gt;` for `>`, etc.\n",
    "   - Simple cards with a single sentence and no code/math may not require special formatting\n",
    "\n",
    "2. Preserve all images and media from the original note\n",
    "\n",
    "3. Format code correctly:\n",
    "   - Multi-line code: Use code blocks with language specification\n",
    "     ```<language>\n",
    "     <code>\n",
    "     ```\n",
    "   - Single-line commands: Use inline code blocks, e.g., `command`\n",
    "\n",
    "4. Format mathematical equations properly:\n",
    "   - Wrap in LaTeX blocks: $ <equation> $\n",
    "   - Avoid double backslashes (\\\\) within LaTeX blocks\n",
    "\n",
    "5. Maintain the original note's intent and key information\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Provide your evaluation as follows:\n",
    "\n",
    "1. A concise reasoning for your assessment, highlighting any formatting issues or improvements\n",
    "2. A boolean verdict: \n",
    "   - `True` if the improved note is correctly formatted\n",
    "   - `False` if the improved note has formatting issues\n",
    "\n",
    "Example output:\n",
    "```\n",
    "Reasoning: The improved note correctly uses hybrid markdown, preserves images, and properly formats code and equations. Line breaks are appropriately handled with <br> tags.\n",
    "\n",
    "Verdict: True\n",
    "```\n",
    "\n",
    "Remember, the original note serves as a reference to ensure the improved version preserves the intended content and any necessary media or code examples.\n",
    "\"\"\"\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat,\n",
    "    system_msg=SYSTEM_MSG_V6,\n",
    "    user_msg_tmpl=user_msg_tmpl,\n",
    "    review_model=Review2,\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa34df-c8c5-4e89-8324-d153458a15a2",
   "metadata": {},
   "source": [
    "Let's see if Meta AI can help here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ff80ce-6650-4912-8f87-fb78628fa084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: True\n",
      "Verdict: guid='\"bv5;TaZ#F2\"' reasoning='The improved note uses hybrid markdown format, preserves images and media, and formats code using code blocks. However, it does not format the inline code block (git submodule add) correctly. It should be formatted as (git submodule add).' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='DkiJ0e50/*' reasoning='The original note is a simple definition. To improve it, we need to format it properly using markdown and preserve the image and tags.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='rvo9[&8:`q' reasoning='The improved note should be factually equivalent to the original note, and the provided original note is a simple definition. To improve the formatting, we need to consider the evaluation criteria. However, the original note does not contain any code, images, or mathematical equations, so the improved note should be identical to the original note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='I@*6RLEsm]' reasoning='The original note is properly formatted, but the improved note is not provided. However, I can provide an example of how the improved note should be formatted based on the evaluation criteria.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='v5I1<L+^4k' reasoning='The provided note is simple and does not require complex formatting. However, to evaluate the improved note, I will assume the original note is as follows:' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='if[&q~T8?V' reasoning='The improved note should use hybrid markdown format, preserve images and media, format code, and format mathematical equations. However, in this case, there are no images, media, or mathematical equations to preserve or format. The code is properly formatted using inline code blocks. The note is concise and factually equivalent to the original note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='L~{D]VMy.2' reasoning='The original note is properly formatted, but the improved note is not provided. However, I can provide an example of how the improved note should be formatted based on the given criteria.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='HhbnT=2&rE' reasoning='The original note is a simple text note with a clear front and back, and relevant tags.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='\"fmc=2!5#q6\"' reasoning='The original note is properly formatted. However, to provide an improved note, I will make some minor adjustments to improve conciseness and formatting.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='gy}T)rqdHN' reasoning='The original note is a simple note with a front, back, and tags. It does not contain any complex formatting such as images, code blocks, or mathematical equations.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='w`zo)Q_qy+' reasoning='The original note is properly formatted. It uses a simple text format without any specific formatting requirements. However, to improve it, we can apply the suggested formatting rules.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='IT@~i{IUdV' reasoning='The improved note should use hybrid markdown format, preserve images and media, format code, and format mathematical equations using LaTeX blocks. The given improved note uses LaTeX blocks for the mathematical equation, but it does not format the code. The original note does not contain any code, so this is not a requirement. However, the improved note does not use hybrid markdown format for the new line in the front. The improved note is factually equivalent to the original note, but it does not meet all the formatting requirements.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='K!d9iKR(l.' reasoning=\"The improved note uses hybrid markdown format, preserves the original code block, and formats it correctly. The code block is a bash code block, and it uses <br> for new lines. The improved note also uses inline code blocks for the command 'cd' and the path variable, but it is not necessary in this case. The note is factually equivalent to the original note.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Q6:mO,Jhsr' reasoning='The original note is properly formatted. It uses a simple and clear format for the front and back sides, and includes relevant tags. However, to meet the requirements, we need to improve the formatting.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='Fx`~EpZmiv' reasoning=\"The original note is a simple text note with a recipe. To improve it, we need to format the text and add tags. Here's an improved version:\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='cvfN4!L{Z$' reasoning='The original note is properly formatted, but the improved note is not provided. However, I can provide an example of an improved note based on the evaluation criteria.' is_correct=False\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"oTs#3>}F=R\"' reasoning='The improved note uses hybrid markdown format, preserves images and media, and formats code using code blocks and inline code blocks. However, the improved note does not format the mathematical equation (in this case, none) using LaTeX blocks. The note is factually equivalent to the original note and has conciseness and formatting improvements.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='i@-NAwld)K' reasoning=\"The original note is a simple text note. To improve it, we need to format it according to the given criteria. However, the original note does not contain any code, images, or mathematical equations, so we can't evaluate the formatting of those elements. The note is concise and factually equivalent to the original note. The tags are properly formatted as a list.\" is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"q#vzRG_1K)\"' reasoning='The original note is properly formatted. It uses a simple text format without any specific formatting requirements. However, to improve it, we can apply the suggested formatting rules.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='DYW.*!vn5h' reasoning='The improved note uses LaTeX blocks for mathematical equations, which is in line with the evaluation criteria. However, the original note does not contain any images or media, so this requirement is not applicable. The note also does not contain any code, so the code formatting requirement is also not applicable. The note is factually equivalent to the original note, and the formatting is concise and improved.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='Lmx76,DaUH' reasoning='The original note is properly formatted. It uses the hybrid markdown format, preserves the image and media, and formats the code using inline code blocks. The mathematical equation is not present in this note, so it is not applicable. The note is concise and factually equivalent to the original note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: True\n",
      "Verdict: guid='\"mT#|Xn4={M\"' reasoning='The original note is a simple statement about PCIe 5.0 bandwidth. It does not contain any images, media, code, or mathematical equations. Therefore, the improved note should be factually equivalent to the original note and use proper formatting.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='A;s3RYgV{-' reasoning='The original note is properly formatted, but it does not contain any images, code, or mathematical equations. Therefore, it meets the requirements for a properly formatted note.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='BMM-Krxd6X' reasoning='The original note is a simple definition note. It does not contain any images, media, code, or mathematical equations. Therefore, the improved note should be factually equivalent to the original note and should not require any formatting changes.' is_correct=True\n",
      "#######################\n",
      "Ground Truth: False\n",
      "Verdict: guid='ww`TG:@YSC' reasoning='The original note is properly formatted. It uses a simple and clear format for the front and back sides, and the tags are correctly enclosed in square brackets. However, it does not use any advanced formatting features such as code blocks, inline code, or LaTeX equations. Therefore, the improved note should be factually equivalent to the original note and should not introduce any new formatting features that are not present in the original note.' is_correct=True\n",
      "#######################\n",
      "Alignment: 12/25 (48.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG_V7 = r\"\"\"# Anki Note Formatting Evaluation\n",
    "Provide two Anki notes:\n",
    "\n",
    "Original Note\n",
    "Front: <original front>\n",
    "Back: <original back>\n",
    "Tags: <original tags>\n",
    "\n",
    "Improved Note\n",
    "Front: <improved front>\n",
    "Back: <improved back>\n",
    "Tags: <improved tags>\n",
    "\n",
    "# Evaluation Criteria\n",
    "Assess the formatting of the improved note, ensuring it:\n",
    "1. Uses hybrid markdown format (e.g., <br> for new lines, &lt; for < symbol)\n",
    "2. Preserves images and media from the original note\n",
    "3. Formats code using:\n",
    "  * Code blocks (<language><br><command><br>) for multiple lines\n",
    "  * Inline code blocks () for single-line commands (e.g., iw, d, :copen)\n",
    "4. Formats mathematical equations using LaTeX blocks ($ <math equation> $) without double backslashes (\\\\)\n",
    "\n",
    "# Requirements\n",
    "* The improved note should be factually equivalent to the original note.\n",
    "* Conciseness and formatting im4provements are expected.\n",
    "\n",
    "# Response Format\n",
    "Provide:\n",
    "* A concise reasoning for your evaluation\n",
    "* A boolean answer: True (improved note is properly formatted) or False (improved note is not properly formatted)\n",
    "\"\"\"\n",
    "\n",
    "judge_json = LLMJudgeJSON(\n",
    "    chat=chat,\n",
    "    system_msg=SYSTEM_MSG_V7,\n",
    "    user_msg_tmpl=user_msg_tmpl,\n",
    "    review_model=Review2,\n",
    ")\n",
    "review_notes(ra=ra, judge=judge_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cd23e-babc-44ac-beda-620612639b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a74e9f-98d1-4d0e-86d1-527765dd7e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771306d-bed4-4edd-bfbf-d4b3db424d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "017974df-4813-447e-8b53-ee6fae73c622",
   "metadata": {},
   "source": [
    "### Create helper functions to facilitate reviewing notes\n",
    "\n",
    "Let's create a `pandas.DataFrame` with both: original note, edited note, and LLM review. This will facilitate our review of the LLM reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1dbc6e0-3656-4063-94b0-242b065ad501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bv5;TaZ#F2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DkiJ0e50/*</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rvo9[&amp;8:`q</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I@*6RLEsm]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v5I1&lt;L+^4k</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         guid  score\n",
       "0  bv5;TaZ#F2   True\n",
       "1  DkiJ0e50/*   True\n",
       "2  rvo9[&8:`q   True\n",
       "3  I@*6RLEsm]  False\n",
       "4  v5I1<L+^4k   True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"../data/eval.txt\", sep=\"\\t\", header=None)\n",
    "df_eval.columns = [\"guid\", \"score\"]\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf1acc2-cd57-43bd-8eb5-ddc7751151b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m ra\u001b[38;5;241m.\u001b[39m_ReviewApp__reviews\n\u001b[0;32m----> 2\u001b[0m dict_data \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mdict() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m      3\u001b[0m df_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dict_data)\n\u001b[1;32m      4\u001b[0m df_scores\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m ra\u001b[38;5;241m.\u001b[39m_ReviewApp__reviews\n\u001b[0;32m----> 2\u001b[0m dict_data \u001b[38;5;241m=\u001b[39m [\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m      3\u001b[0m df_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dict_data)\n\u001b[1;32m      4\u001b[0m df_scores\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dict'"
     ]
    }
   ],
   "source": [
    "results = ra._ReviewApp__reviews\n",
    "dict_data = [item.dict() for item in results]\n",
    "df_scores = pd.DataFrame(dict_data)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f345c24-71b9-4b66-9851-a41df05a967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [note.dict() for note in deck]\n",
    "df_notes = pd.DataFrame(a)\n",
    "df_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe3d5f-5f7e-4004-a8be-0a041b18f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(df_notes, df_scores, how=\"inner\", on=\"guid\")\n",
    "x = x[x.tags.apply(lambda a: \"life\" not in a)]  # exclude personal notes\n",
    "print(x.shape)\n",
    "x.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67017da-94d2-41bf-b141-3f59f5caddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_interactive_session(session_text):\n",
    "    lines = session_text.strip().split(\"<br>\")\n",
    "    input_pattern = r\"^>>> .*$\"\n",
    "    continuation_pattern = r\"^... .*$\"\n",
    "    output_pattern = r\"^(?!>>>)(?!\\.\\.\\.)\"\n",
    "\n",
    "    state = \"expecting_input\"\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        if state == \"expecting_input\":\n",
    "            if not (\n",
    "                re.match(input_pattern, line) or re.match(continuation_pattern, line)\n",
    "            ):\n",
    "                return False, f\"Line {i}: Expected input (>>> or ...), got: {line}\"\n",
    "            state = \"optional_output\"\n",
    "        elif state == \"optional_output\":\n",
    "            if re.match(input_pattern, line) or re.match(continuation_pattern, line):\n",
    "                state = \"expecting_input\"\n",
    "            elif not re.match(output_pattern, line):\n",
    "                return False, f\"Line {i}: Invalid output format: {line}\"\n",
    "\n",
    "    return True, \"Valid interactive session format\"\n",
    "\n",
    "\n",
    "def validate_code_block_format(block):\n",
    "    # Check if the block starts and ends with ```\n",
    "    if not (block.startswith(\"```\") and block.endswith(\"```\")):\n",
    "        return False, \"Code block should start and end with ```\"\n",
    "\n",
    "    # Remove the opening and closing ```\n",
    "    content = block[3:-3].strip()\n",
    "\n",
    "    # Check if the block starts with a language specifier\n",
    "    if not re.match(r\"^[\\w-]+<br>\", content):\n",
    "        return (\n",
    "            False,\n",
    "            \"Code block should start with a language specifier followed by <br>\",\n",
    "        )\n",
    "\n",
    "    # Split the content by <br> tags\n",
    "    lines = content.split(\"<br>\")\n",
    "\n",
    "    # Check if the last line is empty (as it should end with <br>)\n",
    "    if lines[-1].strip() != \"\":\n",
    "        return False, \"Code block should end with <br>\"\n",
    "\n",
    "    # Check if there are any empty lines in between (which would indicate missing <br>)\n",
    "    if any(line.strip() == \"\" for line in lines[1:-1]):\n",
    "        return (\n",
    "            False,\n",
    "            \"Code block should not have empty lines. Use <br> for line breaks.\",\n",
    "        )\n",
    "\n",
    "    return True, \"Valid code block format\"\n",
    "\n",
    "\n",
    "def validate_hybrid_markdown(content):\n",
    "    issues = []\n",
    "\n",
    "    # Check for double backslashes in LaTeX blocks\n",
    "    latex_blocks = re.findall(r\"\\$(.*?)\\$\", content, re.DOTALL)\n",
    "    for block in latex_blocks:\n",
    "        if \"\\\\\\\\\" in block:\n",
    "            issues.append(\n",
    "                \"Double backslash (\\\\\\\\) found in LaTeX block. This may cause rendering issues.\"\n",
    "            )\n",
    "\n",
    "    # Check for unmatched dollar signs\n",
    "    # Split the content into code blocks and non-code blocks\n",
    "    parts = re.split(r\"(```[\\s\\S]*?```)\", content)\n",
    "\n",
    "    total_dollar_count = 0\n",
    "    for part in parts:\n",
    "        if part.startswith(\"```\") and part.endswith(\"```\"):\n",
    "            # This is a code block\n",
    "            is_valid, message = validate_code_block_format(part)\n",
    "            if not is_valid:\n",
    "                issues.append(f\"Invalid code block format: {message}\")\n",
    "\n",
    "            if part.startswith(\"```python\"):\n",
    "                # Check if it's an interactive Python session\n",
    "                session_content = part[13:-3].strip()  # Remove ```python<br> and ```\n",
    "                is_valid, message = validate_interactive_session(session_content)\n",
    "                if not is_valid:\n",
    "                    issues.append(\n",
    "                        f\"Invalid Python interactive session in code block: {message}\"\n",
    "                    )\n",
    "        else:\n",
    "            # Count dollar signs in non-code block parts\n",
    "            dollar_count = part.count(\"$\")\n",
    "            total_dollar_count += dollar_count\n",
    "\n",
    "    # Check if the total number of dollar signs outside code blocks is odd\n",
    "    if total_dollar_count % 2 != 0:\n",
    "        issues.append(\n",
    "            \"Unmatched dollar signs outside code blocks. LaTeX may not render correctly.\"\n",
    "        )\n",
    "\n",
    "    # Check for common Markdown syntax errors\n",
    "    if \"```\" in content and content.count(\"```\") % 2 != 0:\n",
    "        issues.append(\n",
    "            \"Unmatched code block delimiters (```). Code blocks may not render correctly.\"\n",
    "        )\n",
    "\n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de65941-7107-4a17-88cc-3590d0f1ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reviews = 100\n",
    "\n",
    "for row in x.iloc[:n_reviews].iterrows():\n",
    "    note = row[1]\n",
    "    print(f\"Front: {note['front']}\\nBack: {note['back']}\\nTags: {note['tags']}\")\n",
    "    for side in [\"front\", \"back\"]:\n",
    "        a = note[side]\n",
    "        issues = validate_hybrid_markdown(a)\n",
    "        if issues:\n",
    "            for issue in issues:\n",
    "                print(f\"Issue {side}: {issue}\")\n",
    "        else:\n",
    "            print(f\"Issue {side}: None\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9168c-46f6-49a7-851b-4b23a9669aff",
   "metadata": {},
   "source": [
    "Common errors are:\n",
    "\n",
    "* Missing `<img>`\n",
    "* Wrong prompt (e.g., `>>`, missing `$`)\n",
    "* Missing `<br>` inside code block\n",
    "* Missing `<br>` outside code block\n",
    "* `\\\\` in LaTeX\n",
    "* References (should we remove them?)\n",
    "* Trailing `.` (full stop)\n",
    "* Using code block for note that does not contain code\n",
    "* \"```bash\" for keymap\n",
    "* Missing language in code block\n",
    "* Unmatched code block delimiter (missing trailing \"```\")\n",
    "* Missing inline code block for keymap or short commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fc84d-92e4-4f4a-a84f-cd96d9921e5b",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "- [ ] Create a dataset to measure LLM judge's alignment with human preference \n",
    "- [ ] Use _reflection_ agentic workflow to improve notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096944a4-fb5c-47b1-ac86-88ac99949927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
