{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfc59c0-44ee-4c92-a592-5c7701887fb9",
   "metadata": {},
   "source": [
    "# LLM as a Judge\n",
    "\n",
    "So far, we have been manually reviewing the LLM editor's outputs. This has been a relatively smooth process, but it is not scalable, as there are many failure cases we would need to keep track of. Investing in building an LLM judge makes sense at this stage. \n",
    "\n",
    "Before deploying an LLM judge, we need to ensure its performance is aligned with that of a human judge. This is critical as we would otherwise risk optimizing the wrong metric.\n",
    "\n",
    "Let's get started by creating a small human-annotated dataset of reviews. This dataset will later be used to evaluate the performance of our LLM judge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a75b2-92ac-45fc-b93e-7e2c3326f0a2",
   "metadata": {},
   "source": [
    "### Create an Eval dataset\n",
    "\n",
    "To ease the process of creating an eval dataset, we built a small utility class, `ReviewApp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2604a72f-363e-4aa8-8f59-531135520961",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7291c877-6479-4973-b5c9-a6f62d6dbbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from json.decoder import JSONDecodeError\n",
    "from typing import cast\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from anki_ai.domain.model import Deck, Note\n",
    "from anki_ai.entrypoints.review_notes_changes import ReviewApp\n",
    "from anki_ai.service_layer.services import (\n",
    "    ChatCompletionsService,\n",
    "    get_chat_completion,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53f6d7d-111d-4b1e-852d-b81f8edc16e1",
   "metadata": {},
   "source": [
    "We have collected annotations for over 200 notes. We will use this dataset to evaluate the model's alignment with our preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387bd2a9-04cb-44f3-b53e-2d1ae92e7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_deck = Deck(\"original\")\n",
    "orig_deck.read_txt(\"../data/Selected Notes v7.txt\")\n",
    "\n",
    "deck = Deck(\"edited\")\n",
    "deck.read_txt(\"../data/new_deck.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9777f93-d89f-4f60-b698-abb5e184052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = ReviewApp(deck=deck)\n",
    "ra.load(\"../data/eval.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8166ca7a-4b17-4645-9547-6e5047bdb116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A$U26&gt;n14?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c#*tMdp`:C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hVkGAdktL6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yyo348j{|9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N1O$1BYpt$</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         guid  score\n",
       "0  A$U26>n14?  False\n",
       "1  c#*tMdp`:C   True\n",
       "2  hVkGAdktL6   True\n",
       "3  yyo348j{|9   True\n",
       "4  N1O$1BYpt$   True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"../data/eval.txt\", sep=\"\\t\", header=None)\n",
    "df_eval.columns = [\"guid\", \"score\"]\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0c191-315e-481a-9aa0-cfe92e427678",
   "metadata": {},
   "source": [
    "### Create a very simple LLM judge\n",
    "\n",
    "Let's create a simple LLM judge, and evaluate its alignment with human preference by measuring how well it does on the eval dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47198333-9083-4c84-82ca-fdf3ccfff28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = r\"\"\"\n",
    "Your job is to evaluate Anki's notes and classify notes that are not formatted correctly.\n",
    "\n",
    "Requirements:\n",
    "* Only check formatting\n",
    "* Notes are written in hybrid markdown; for instance: the newline character is `<br>,` `<` is `&lt;`, etc.\n",
    "* Preserve images and media on the original note\n",
    "* Use code block: ```<language><br><command><br>```\n",
    "* Use inline code format for short commands: e.g., `iw`, `d`, etc.\n",
    "\n",
    "Provide only a boolean score: False for bad and True for good.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def review_note(note: Note, chat: ChatCompletionsService) -> Note:\n",
    "    user_msg = f\"\"\"Front: {note.front}\\nBack: {note.back}\\nTags: {note.tags}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ]\n",
    "\n",
    "    chat_response = chat.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        messages=messages,  # type: ignore\n",
    "        temperature=0,\n",
    "    )\n",
    "    result: str = cast(str, chat_response.choices[0].message.content)\n",
    "\n",
    "    print(user_msg)\n",
    "    print(f\"Eval: {result}\")\n",
    "    return eval(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1aeecd4-cf19-4c31-9d71-0e3deb1f901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front: Locker\n",
      "Back: Locker\n",
      "Tags: ['english']\n",
      "Eval: False\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Character-level vs word-level tokenization\n",
      "Back: Character-level tokenizers have much smaller vocabularies\n",
      "Tags: ['nlp']\n",
      "Eval: False\n",
      "\n",
      "Reason: The note is missing a newline character after the front and back fields. It should be formatted as:\n",
      "\n",
      "Front: Character-level vs word-level tokenization<br>\n",
      "Back: Character-level tokenizers have much smaller vocabularies<br>\n",
      "Tags: ['nlp']\n",
      "\n",
      "The LLM did not comply with the prompt and returned something different from True or False: invalid syntax (<string>, line 3)\n"
     ]
    }
   ],
   "source": [
    "chat = get_chat_completion()\n",
    "\n",
    "aligned = 0\n",
    "tot = 0\n",
    "try:\n",
    "    for guid, score in ra._ReviewApp__reviews.items():\n",
    "        note = deck.get(guid=guid)[0]\n",
    "        pred = review_note(note, chat)\n",
    "        print(f\"Ground Truth: {score}\\n\")\n",
    "        if pred == score:\n",
    "            aligned += 1\n",
    "        tot += 1\n",
    "        print(\"#######################\\n\")\n",
    "\n",
    "    print(f\"Alignment: {aligned / tot:.2%}\")\n",
    "except SyntaxError as e:\n",
    "    print(\n",
    "        f\"\\nThe LLM did not comply with the prompt and returned something different from True or False: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69ebec-724d-4b22-bd20-f42c9a12c220",
   "metadata": {},
   "source": [
    "This first model doesn't do well on the task. Let's try to improve it by using structured output and few-shot learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae7ac6-d84f-43a5-99d9-a798939737c7",
   "metadata": {},
   "source": [
    "### Improve performance of LLM judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd0d8c-ca82-4573-a82b-46e9996552bf",
   "metadata": {},
   "source": [
    "#### Structured output\n",
    "\n",
    "The LLM judge's performance seems decent, but we should use structured output to make it more manageable and avoid scenarios when the LLM does not follow the instructions properly and returns something other than a boolean. This can happen quite frequently. To address that, let's use structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd89758-9c43-4994-a6e0-5515072a0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review(BaseModel):\n",
    "    guid: str\n",
    "    is_correct: bool\n",
    "\n",
    "def review_note(note: Note, chat: ChatCompletionsService, verbose=False) -> Note:\n",
    "    user_msg = f\"\"\"Front: {note.front}\\nBack: {note.back}\\nTags: {note.tags}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ]\n",
    "    extra_body = {\n",
    "        \"guided_json\": Review.model_json_schema(),\n",
    "        \"guided_whitespace_pattern\": r\"[\\n\\t ]*\",\n",
    "    }\n",
    "\n",
    "    chat_response = chat.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        messages=messages,  # type: ignore\n",
    "        temperature=0,\n",
    "        extra_body=extra_body,\n",
    "    )\n",
    "    content_str: str = cast(str, chat_response.choices[0].message.content)\n",
    "    try:\n",
    "        content_dict = json.loads(content_str)\n",
    "        content_dict[\"guid\"] = note.guid\n",
    "        updated_content_str = json.dumps(content_dict)\n",
    "        result = Review.model_validate_json(updated_content_str)\n",
    "\n",
    "        if verbose:\n",
    "            print(user_msg)\n",
    "            print(f\"Eval: {result}\\n\")\n",
    "\n",
    "        return result\n",
    "    except JSONDecodeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423215c2-1cf3-44bd-a050-0eadc71df0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front: Locker\n",
      "Back: Locker\n",
      "Tags: ['english']\n",
      "Eval: guid='A$U26>n14?' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Character-level vs word-level tokenization\n",
      "Back: Character-level tokenizers have much smaller vocabularies\n",
      "Tags: ['nlp']\n",
      "Eval: guid='\"c#*tMdp`:C\"' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Chipset PCIe lanes name\n",
      "Back: PCH lanes\n",
      "Tags: ['gpu', 'hardware']\n",
      "Eval: guid='hVkGAdktL6' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: WebSockets vs traditional web communication\n",
      "Back: HTTP follows a request-response model. WebSockets introduce a full-duplex communication channel\n",
      "Tags: ['system-design']\n",
      "Eval: guid='yyo348j{|9' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Test Time Augmentation\n",
      "Back: At inference/validation time, create multiple versions of each image using data augmentation, then take the average/max of predictions for each version.\n",
      "Tags: ['fastai']\n",
      "Eval: guid='N1O$1BYpt$' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Left-handed golf stance\n",
      "Back: Feet and knees aligned with target line, weight on left foot, clubface open 10-15 degrees\n",
      "Tags: ['golf']\n",
      "Eval: guid='MPiZ(&lAxK' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Working Capital use\n",
      "Back: To gauge the short-term health of an organization\n",
      "Tags: ['finance']\n",
      "Eval: guid='J1um1e@6EN' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: New tab keymap\n",
      "Back: `t`\n",
      "Tags: ['vimium']\n",
      "Eval: guid='cAGU,We~`~' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Increment HashMap value\n",
      "Back: ```rust<br>match map.get(&w) {<br>    Some(count) => { map.insert(w, count + 1); }<br>    None => { map.insert(w, 1); }<br>}\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='u,FyN]W/|%' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Open all folds\n",
      "Back: `zR` — Reduce folds (opens all folds)\n",
      "Tags: ['nvim']\n",
      "Eval: guid='\"fC+uI=1h#=\"' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Assign `s1` to `s2`\n",
      "Back: `s1` is invalidated. Consider using `s1.clone()` instead.\\n```bash\"> cargo run\"> Compiling ownership v0.1.0 (file:///projects/ownership)\"> error[E0382]: borrow of moved value: `s1`\">  --> src/main.rs:5:28\">  |\"> 2 |     let s1 = String::from(\"\"hello\"\");\">  |         -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait\"> 3 |     let s2 = s1;\">  |              -- value moved here\"> 4 |\"> 5 |     println!(\"\"{} world!\"\", s1);\">  |                            ^^ value borrowed here after move\">  |\">  = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info)\"> help: consider cloning the value if the performance cost is acceptable\">  |\"> 3 |     let s2 = s1.clone();\">  |                ++++++++\"> For more information about this error, try `rustc --explain E0382`.\"> error: could not compile `ownership` due to previous error\"> ```\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='sefDNl}8>v' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Text preprocessing for Transformer model\n",
      "Back: TokenizationNumericalization\n",
      "Tags: ['nlp']\n",
      "Eval: guid='D;FouTT/-X' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: The windshield is steaming up\n",
      "Back: The windshield is fogging up due to high humidity or temperature difference.\n",
      "Tags: ['english']\n",
      "Eval: guid='\"g~#puI)*I%\"' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Get command manual/help\n",
      "Back: ```bash<br>$ man <command><br>```\n",
      "Tags: ['linux']\n",
      "Eval: guid='s=l*N,i*FW' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: $ \\\\[\\frac{\\partial}{\\partial x} [f(x) - g(x)] = {{c1:: \\frac{\\partial}{\\partial x} f(x) - \\frac{\\partial}{\\partial x} g(x) }} \\]$\n",
      "Back: Difference Rule\n",
      "Tags: ['math']\n",
      "Eval: guid='fqco;Q7@H~' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Brig's favorite food\n",
      "Back: Sandwiches\n",
      "Tags: ['life']\n",
      "Eval: guid='MaS+8AHK*6' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Accuracy formula\n",
      "Back: $\\\\[math] \\\\[text{ACC} = \\frac{ \\text{TP} + \\text{TN} }{ \\text{TP} + \\text{FP} + \\text{TN} + \\text{FN} } \\[/math] $\n",
      "Tags: ['classification', 'ml']\n",
      "Eval: guid='bd[&6V7P?]' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: DJIA meaning\n",
      "Back: Dow Jones Industrial Average\n",
      "Tags: ['finance']\n",
      "Eval: guid='m%{1B{Q1jr' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Bayes Theorem conditional probability\n",
      "Back: The posterior\n",
      "Tags: ['stats']\n",
      "Eval: guid='JW|~i]cGSh' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Jaccard index synonym\n",
      "Back: Intersection over union\n",
      "Tags: ['ml']\n",
      "Eval: guid='MrC556~`Pm' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: SSL meaning\n",
      "Back: Self-supervised learning\n",
      "Tags: ['ml']\n",
      "Eval: guid='pJ8P[<D3z&' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Document mimicry\n",
      "Back: A form of prompting which consists in trying to mimic as closely as possible the format of documents that the LLM saw during training (e.g., a conversation transcript)\n",
      "Tags: ['llm']\n",
      "Eval: guid='x43Ud=[8]O' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Presizing initial validation set resizing\n",
      "Back: The center square of the image is always chosen\n",
      "Tags: ['dl', 'fastai', 'ml']\n",
      "Eval: guid='AY+9%meG%9' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Docker ps meaning\n",
      "Back: [p]rocess [s]tatus\n",
      "Tags: ['docker']\n",
      "Eval: guid='Mmzr]&:9e0' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Open older quickfix list\n",
      "Back: :colder\n",
      "Tags: ['nvim']\n",
      "Eval: guid='b~pDqG>Kbv' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Alignment: 17/25 (68.00%)\n"
     ]
    }
   ],
   "source": [
    "chat = get_chat_completion()\n",
    "\n",
    "aligned = 0\n",
    "tot = 0\n",
    "for guid, score in ra._ReviewApp__reviews.items():\n",
    "    note = deck.get(guid=guid)[0]\n",
    "    pred = review_note(note, chat, verbose=True)\n",
    "    print(f\"Ground Truth: {score}\\n\")\n",
    "    if pred.is_correct == eval(score):\n",
    "        aligned += 1\n",
    "    tot += 1\n",
    "    print(\"#######################\\n\")\n",
    "\n",
    "print(f\"Alignment: {aligned}/{tot} ({aligned / tot:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aaf054-fda7-458e-b97b-e51592169880",
   "metadata": {},
   "source": [
    "#### Few-shot prompting\n",
    "\n",
    "Some of the answers are incorrect. Let's try to pass a few examples to the LLM judge to see if we can improve on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b383fbd-c077-46e4-9c2d-b2412a788d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = r\"\"\"\n",
    "Your job is to evaluate Anki notes, and classify notes that are not formatted correctly.\n",
    "\n",
    "Requirements:\n",
    "* Only check formatting\n",
    "* Notes should be in HTML format; for instance: newline should \"<br>\", \"<\" should be \"&lt;\", etc.\n",
    "* Preserve images and media on the original note\n",
    "* Use code block: ```<language><br><command><br>```\n",
    "* Use inline code format for very short commands: `iw`, `d`, etc.\n",
    "\n",
    "Examples of good notes:\n",
    "\n",
    "Example 1:\n",
    "\n",
    "    Front: Create soft link\n",
    "    Back:  ```bash<br>$ ln -s <file> <link><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Example 2:\n",
    "\n",
    "    Front: Zip destination option\n",
    "    Back:  ```bash<br>$ unzip <file> -d <path><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Example 3:\n",
    "\n",
    "    Front: Extract zip files\n",
    "    Back:  ```bash<br>$ unzip <file><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Example 4:\n",
    "\n",
    "    Front: List directory content\n",
    "    Back:  ```bash<br>$ ls <path><br>```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "Examples of bad notes: \n",
    "\n",
    "Example 1:\n",
    "\n",
    "    Front: Return to previous directory\n",
    "    Back:  ```bash $ cd -```\n",
    "    Tags:  ['linux']\n",
    "\n",
    "    Reasoning: Missing newlines (<br> tags) in code block\n",
    "\n",
    "Example 2: \n",
    "\n",
    "    Front: Remove delimiters\n",
    "    Back:  ```ds <delimiter>```\n",
    "    Tags:  ['nvim']\n",
    "\n",
    "    Reasoning: Using triple backtick quotes without specifying the language and adding newlines (<br> tag) in code block\n",
    "\n",
    "Example 3: \n",
    "\n",
    "    Front: Change Anki delimiters\n",
    "    Back:  ```\\\n",
    "    Tags:  ['nvim']\n",
    "    \n",
    "    Reasoning: Mentioning the command is an Anki command when, in fact, it's a nvim command\n",
    "\n",
    "Example 4: \n",
    "\n",
    "    Front: Text object for a sentence\n",
    "    Back:  ```\\\n",
    "    Tags:  ['nvim']\n",
    "    \n",
    "    Reasoning: Missing command and not closing code block\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def review_note(note: Note, chat: ChatCompletionsService, verbose=False) -> Note:\n",
    "    user_msg = f\"\"\"Front: {note.front}\\nBack: {note.back}\\nTags: {note.tags}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ]\n",
    "    extra_body = {\n",
    "        \"guided_json\": Review.model_json_schema(),\n",
    "        \"guided_whitespace_pattern\": r\"[\\n\\t ]*\",\n",
    "    }\n",
    "\n",
    "    chat_response = chat.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        messages=messages,  # type: ignore\n",
    "        temperature=0,\n",
    "        extra_body=extra_body,\n",
    "    )\n",
    "    content_str: str = cast(str, chat_response.choices[0].message.content)\n",
    "    try:\n",
    "        content_dict = json.loads(content_str)\n",
    "        content_dict[\"guid\"] = note.guid\n",
    "        updated_content_str = json.dumps(content_dict)\n",
    "        result = Review.model_validate_json(updated_content_str)\n",
    "\n",
    "        if verbose:\n",
    "            print(user_msg)\n",
    "            print(f\"Eval: {result}\\n\")\n",
    "\n",
    "        return result\n",
    "    except JSONDecodeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb4398a-5d79-434b-8207-b789c1f60597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front: Locker\n",
      "Back: Locker\n",
      "Tags: ['english']\n",
      "Eval: guid='A$U26>n14?' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Character-level vs word-level tokenization\n",
      "Back: Character-level tokenizers have much smaller vocabularies\n",
      "Tags: ['nlp']\n",
      "Eval: guid='\"c#*tMdp`:C\"' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Chipset PCIe lanes name\n",
      "Back: PCH lanes\n",
      "Tags: ['gpu', 'hardware']\n",
      "Eval: guid='hVkGAdktL6' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: WebSockets vs traditional web communication\n",
      "Back: HTTP follows a request-response model. WebSockets introduce a full-duplex communication channel\n",
      "Tags: ['system-design']\n",
      "Eval: guid='yyo348j{|9' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Test Time Augmentation\n",
      "Back: At inference/validation time, create multiple versions of each image using data augmentation, then take the average/max of predictions for each version.\n",
      "Tags: ['fastai']\n",
      "Eval: guid='N1O$1BYpt$' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Left-handed golf stance\n",
      "Back: Feet and knees aligned with target line, weight on left foot, clubface open 10-15 degrees\n",
      "Tags: ['golf']\n",
      "Eval: guid='MPiZ(&lAxK' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Working Capital use\n",
      "Back: To gauge the short-term health of an organization\n",
      "Tags: ['finance']\n",
      "Eval: guid='J1um1e@6EN' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: New tab keymap\n",
      "Back: `t`\n",
      "Tags: ['vimium']\n",
      "Eval: guid='cAGU,We~`~' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Increment HashMap value\n",
      "Back: ```rust<br>match map.get(&w) {<br>    Some(count) => { map.insert(w, count + 1); }<br>    None => { map.insert(w, 1); }<br>}\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='u,FyN]W/|%' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Open all folds\n",
      "Back: `zR` — Reduce folds (opens all folds)\n",
      "Tags: ['nvim']\n",
      "Eval: guid='\"fC+uI=1h#=\"' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Assign `s1` to `s2`\n",
      "Back: `s1` is invalidated. Consider using `s1.clone()` instead.\\n```bash\"> cargo run\"> Compiling ownership v0.1.0 (file:///projects/ownership)\"> error[E0382]: borrow of moved value: `s1`\">  --> src/main.rs:5:28\">  |\"> 2 |     let s1 = String::from(\"\"hello\"\");\">  |         -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait\"> 3 |     let s2 = s1;\">  |              -- value moved here\"> 4 |\"> 5 |     println!(\"\"{} world!\"\", s1);\">  |                            ^^ value borrowed here after move\">  |\">  = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info)\"> help: consider cloning the value if the performance cost is acceptable\">  |\"> 3 |     let s2 = s1.clone();\">  |                ++++++++\"> For more information about this error, try `rustc --explain E0382`.\"> error: could not compile `ownership` due to previous error\"> ```\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='sefDNl}8>v' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Text preprocessing for Transformer model\n",
      "Back: TokenizationNumericalization\n",
      "Tags: ['nlp']\n",
      "Eval: guid='D;FouTT/-X' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: The windshield is steaming up\n",
      "Back: The windshield is fogging up due to high humidity or temperature difference.\n",
      "Tags: ['english']\n",
      "Eval: guid='\"g~#puI)*I%\"' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Get command manual/help\n",
      "Back: ```bash<br>$ man <command><br>```\n",
      "Tags: ['linux']\n",
      "Eval: guid='s=l*N,i*FW' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: $ \\\\[\\frac{\\partial}{\\partial x} [f(x) - g(x)] = {{c1:: \\frac{\\partial}{\\partial x} f(x) - \\frac{\\partial}{\\partial x} g(x) }} \\]$\n",
      "Back: Difference Rule\n",
      "Tags: ['math']\n",
      "Eval: guid='fqco;Q7@H~' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Brig's favorite food\n",
      "Back: Sandwiches\n",
      "Tags: ['life']\n",
      "Eval: guid='MaS+8AHK*6' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Accuracy formula\n",
      "Back: $\\\\[math] \\\\[text{ACC} = \\frac{ \\text{TP} + \\text{TN} }{ \\text{TP} + \\text{FP} + \\text{TN} + \\text{FN} } \\[/math] $\n",
      "Tags: ['classification', 'ml']\n",
      "Eval: guid='bd[&6V7P?]' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: DJIA meaning\n",
      "Back: Dow Jones Industrial Average\n",
      "Tags: ['finance']\n",
      "Eval: guid='m%{1B{Q1jr' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Bayes Theorem conditional probability\n",
      "Back: The posterior\n",
      "Tags: ['stats']\n",
      "Eval: guid='JW|~i]cGSh' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Jaccard index synonym\n",
      "Back: Intersection over union\n",
      "Tags: ['ml']\n",
      "Eval: guid='MrC556~`Pm' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: SSL meaning\n",
      "Back: Self-supervised learning\n",
      "Tags: ['ml']\n",
      "Eval: guid='pJ8P[<D3z&' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Document mimicry\n",
      "Back: A form of prompting which consists in trying to mimic as closely as possible the format of documents that the LLM saw during training (e.g., a conversation transcript)\n",
      "Tags: ['llm']\n",
      "Eval: guid='x43Ud=[8]O' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Presizing initial validation set resizing\n",
      "Back: The center square of the image is always chosen\n",
      "Tags: ['dl', 'fastai', 'ml']\n",
      "Eval: guid='AY+9%meG%9' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Docker ps meaning\n",
      "Back: [p]rocess [s]tatus\n",
      "Tags: ['docker']\n",
      "Eval: guid='Mmzr]&:9e0' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Open older quickfix list\n",
      "Back: :colder\n",
      "Tags: ['nvim']\n",
      "Eval: guid='b~pDqG>Kbv' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Alignment: 14/25 (56.00%)\n"
     ]
    }
   ],
   "source": [
    "chat = get_chat_completion()\n",
    "\n",
    "aligned = 0\n",
    "tot = 0\n",
    "for guid, score in ra._ReviewApp__reviews.items():\n",
    "    note = deck.get(guid=guid)[0]\n",
    "    pred = review_note(note, chat, verbose=True)\n",
    "    print(f\"Ground Truth: {score}\\n\")\n",
    "    if pred.is_correct == eval(score):\n",
    "        aligned += 1\n",
    "    tot += 1\n",
    "    print(\"#######################\\n\")\n",
    "\n",
    "print(f\"Alignment: {aligned}/{tot} ({aligned / tot:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc74d3-95ef-4322-a8ea-701f5942e859",
   "metadata": {},
   "source": [
    "This result is also surprising. We would have expected a few examples to help the model understand what is the expected formatting for these notes. \n",
    "\n",
    "A few things we want to try next: \n",
    "1. For each type of common error (e.g., double backslash on LaTeX code, code block for math, etc.), provide both a negative and positive example\n",
    "1. Ask the LLM to provide reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84716b2d-34d7-4a83-8a83-cafb5669535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front: Locker\n",
      "Back: Locker\n",
      "Tags: ['english']\n",
      "Eval: guid='A$U26>n14?' reasoning=\"The front and back of the note are identical, which is not a good practice in Anki. It's better to have a clear and concise front and a detailed back.\" is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Character-level vs word-level tokenization\n",
      "Back: Character-level tokenizers have much smaller vocabularies\n",
      "Tags: ['nlp']\n",
      "Eval: guid='\"c#*tMdp`:C\"' reasoning='The note is properly formatted.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Chipset PCIe lanes name\n",
      "Back: PCH lanes\n",
      "Tags: ['gpu', 'hardware']\n",
      "Eval: guid='hVkGAdktL6' reasoning='The note is properly formatted as it uses the required fields and does not contain any formatting issues.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: WebSockets vs traditional web communication\n",
      "Back: HTTP follows a request-response model. WebSockets introduce a full-duplex communication channel\n",
      "Tags: ['system-design']\n",
      "Eval: guid='yyo348j{|9' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the original note, and does not contain any code or math blocks.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Test Time Augmentation\n",
      "Back: At inference/validation time, create multiple versions of each image using data augmentation, then take the average/max of predictions for each version.\n",
      "Tags: ['fastai']\n",
      "Eval: guid='N1O$1BYpt$' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original note, and does not contain any code, math, or short commands that require special formatting.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Left-handed golf stance\n",
      "Back: Feet and knees aligned with target line, weight on left foot, clubface open 10-15 degrees\n",
      "Tags: ['golf']\n",
      "Eval: guid='MPiZ(&lAxK' reasoning='This note is properly formatted as it uses the required tags and does not contain any code, math, or media that would require special formatting. However, the note could be improved by adding a description or explanation of the left-handed golf stance.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Working Capital use\n",
      "Back: To gauge the short-term health of an organization\n",
      "Tags: ['finance']\n",
      "Eval: guid='J1um1e@6EN' reasoning='The note is properly formatted as it uses the required tags and does not contain any code, math, or media that would require special formatting. However, it is worth noting that the note could be improved by adding a description or definition of working capital use to make it more useful for future reference.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: New tab keymap\n",
      "Back: `t`\n",
      "Tags: ['vimium']\n",
      "Eval: guid='cAGU,We~`~' reasoning=\"The note is using hybrid markdown format, and it preserves the original note's formatting. The back of the note is wrapped in a code block, and the tags are properly formatted.\" is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Increment HashMap value\n",
      "Back: ```rust<br>match map.get(&w) {<br>    Some(count) => { map.insert(w, count + 1); }<br>    None => { map.insert(w, 1); }<br>}\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='u,FyN]W/|%' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the code block, and uses the correct syntax for the code block and tags.' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Open all folds\n",
      "Back: `zR` — Reduce folds (opens all folds)\n",
      "Tags: ['nvim']\n",
      "Eval: guid='\"fC+uI=1h#=\"' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the original note, and wraps the code in a code block. The tags are also properly formatted as a list.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Assign `s1` to `s2`\n",
      "Back: `s1` is invalidated. Consider using `s1.clone()` instead.\\n```bash\"> cargo run\"> Compiling ownership v0.1.0 (file:///projects/ownership)\"> error[E0382]: borrow of moved value: `s1`\">  --> src/main.rs:5:28\">  |\"> 2 |     let s1 = String::from(\"\"hello\"\");\">  |         -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait\"> 3 |     let s2 = s1;\">  |              -- value moved here\"> 4 |\"> 5 |     println!(\"\"{} world!\"\", s1);\">  |                            ^^ value borrowed here after move\">  |\">  = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info)\"> help: consider cloning the value if the performance cost is acceptable\">  |\"> 3 |     let s2 = s1.clone();\">  |                ++++++++\"> For more information about this error, try `rustc --explain E0382`.\"> error: could not compile `ownership` due to previous error\"> ```\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='sefDNl}8>v' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original image/media, wraps code in a code block, and uses inline code blocks for short commands.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Text preprocessing for Transformer model\n",
      "Back: TokenizationNumericalization\n",
      "Tags: ['nlp']\n",
      "Eval: guid='D;FouTT/-X' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the original text, and does not contain any code, math, or short commands that require special formatting. However, it does not wrap the text in a code block, which is not necessary in this case. But since there is no code, it is not required to wrap it in a code block. The note is still properly formatted.' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: The windshield is steaming up\n",
      "Back: The windshield is fogging up due to high humidity or temperature difference.\n",
      "Tags: ['english']\n",
      "Eval: guid='\"g~#puI)*I%\"' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the original note, and does not contain any code, math, or short commands that require special formatting.' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Get command manual/help\n",
      "Back: ```bash<br>$ man <command><br>```\n",
      "Tags: ['linux']\n",
      "Eval: guid='s=l*N,i*FW' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original note, and wraps the code in a code block. The tags are also properly formatted.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: $ \\\\[\\frac{\\partial}{\\partial x} [f(x) - g(x)] = {{c1:: \\frac{\\partial}{\\partial x} f(x) - \\frac{\\partial}{\\partial x} g(x) }} \\]$\n",
      "Back: Difference Rule\n",
      "Tags: ['math']\n",
      "Eval: guid='fqco;Q7@H~' reasoning='The note is properly formatted. The math equation is wrapped in a LaTeX block, and the double backslashes, \\\\, are correctly escaped as $ \\\\[ ... \\\\]$.' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Brig's favorite food\n",
      "Back: Sandwiches\n",
      "Tags: ['life']\n",
      "Eval: guid='MaS+8AHK*6' reasoning='This note is a simple fact note, and it does not contain any special formatting. It is properly formatted.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Accuracy formula\n",
      "Back: $\\\\[math] \\\\[text{ACC} = \\frac{ \\text{TP} + \\text{TN} }{ \\text{TP} + \\text{FP} + \\text{TN} + \\text{FN} } \\[/math] $\n",
      "Tags: ['classification', 'ml']\n",
      "Eval: guid='bd[&6V7P?]' reasoning='The note is using LaTeX for math, but it is incorrectly using double backslashes, \\\\, in the LaTeX block. This will not be correctly displayed in Anki. Also, the note is missing the hybrid markdown format for the front and back of the note.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: DJIA meaning\n",
      "Back: Dow Jones Industrial Average\n",
      "Tags: ['finance']\n",
      "Eval: guid='m%{1B{Q1jr' reasoning='The note is properly formatted as it uses the required tags and does not contain any code, math, or media that would require special formatting. However, the DJIA meaning is not wrapped in an inline code block, which is a recommended practice.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Bayes Theorem conditional probability\n",
      "Back: The posterior\n",
      "Tags: ['stats']\n",
      "Eval: guid='JW|~i]cGSh' reasoning='The note is missing the actual content of the note, so it is difficult to evaluate the formatting. However, the tags are properly formatted as a list in square brackets.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Jaccard index synonym\n",
      "Back: Intersection over union\n",
      "Tags: ['ml']\n",
      "Eval: guid='MrC556~`Pm' reasoning='The note is properly formatted as it uses the required tags and does not contain any formatting issues.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: SSL meaning\n",
      "Back: Self-supervised learning\n",
      "Tags: ['ml']\n",
      "Eval: guid='pJ8P[<D3z&' reasoning='The note is properly formatted as it uses the required tags and the back of the note is in plain text. However, the front of the note could be improved by using a hybrid markdown format.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Document mimicry\n",
      "Back: A form of prompting which consists in trying to mimic as closely as possible the format of documents that the LLM saw during training (e.g., a conversation transcript)\n",
      "Tags: ['llm']\n",
      "Eval: guid='x43Ud=[8]O' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves the original note, and does not contain any code, math, or short commands that require special formatting.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Presizing initial validation set resizing\n",
      "Back: The center square of the image is always chosen\n",
      "Tags: ['dl', 'fastai', 'ml']\n",
      "Eval: guid='AY+9%meG%9' reasoning='The note is properly formatted as it uses hybrid markdown format, preserves images and media, and does not contain any code or math blocks. However, the tags are not properly formatted as they are enclosed in single quotes instead of square brackets. The correct format should be [dl, fastai, ml].' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Docker ps meaning\n",
      "Back: [p]rocess [s]tatus\n",
      "Tags: ['docker']\n",
      "Eval: guid='Mmzr]&:9e0' reasoning='The note is properly formatted. It uses hybrid markdown format, preserves the original note, and uses code blocks and inline code blocks correctly. However, the note does not contain any images or media, but that is not a requirement for a properly formatted note. The tags are also properly formatted.' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Front: Open older quickfix list\n",
      "Back: :colder\n",
      "Tags: ['nvim']\n",
      "Eval: guid='b~pDqG>Kbv' reasoning='The note is properly formatted as it uses the required format for Anki note, with the front and back sides of the note, and tags. However, the note does not contain any special formatting such as code, math, or media, so it is not a comprehensive test of the formatting rules.' is_correct=True\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Alignment: 16/25 (64.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG = r\"\"\"\n",
    "Your job is to evaluate the formatting of Anki note.\n",
    "\n",
    "Properly formatted notes should:\n",
    "* Use hybrid markdown format. For instance, use \"<br>\" to signal a new line, \"&lt;\" for \"<\" symbol, etc.\n",
    "* Preserve images and media on the original note\n",
    "* Wrap code in a code block: ```<language><br><command><br>```\n",
    "* Wrap math in a LaTeX block: $ <math equation> $. Also, ensure that we do not use double backslashes, \\\\, in a LaTeX block, as that won't be correctly displayed\n",
    "* Wrap short commands in an inline code block: `iw`, `d`, etc.\n",
    "\n",
    "Provide concise reasoning for your answer and a True/False answer, where True means the note is formatted correctly and False means the note is not properly formatted.\n",
    "\"\"\"\n",
    "\n",
    "class Review(BaseModel):\n",
    "    guid: str\n",
    "    reasoning: str \n",
    "    is_correct: bool\n",
    "\n",
    "def review_note(note: Note, chat: ChatCompletionsService, verbose=False) -> Note:\n",
    "    user_msg = f\"\"\"Front: {note.front}\\nBack: {note.back}\\nTags: {note.tags}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ]\n",
    "    extra_body = {\n",
    "        \"guided_json\": Review.model_json_schema(),\n",
    "        \"guided_whitespace_pattern\": r\"[\\n\\t ]*\",\n",
    "    }\n",
    "\n",
    "    chat_response = chat.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        messages=messages,  # type: ignore\n",
    "        temperature=0,\n",
    "        extra_body=extra_body,\n",
    "    )\n",
    "    content_str: str = cast(str, chat_response.choices[0].message.content)\n",
    "    try:\n",
    "        content_dict = json.loads(content_str)\n",
    "        content_dict[\"guid\"] = note.guid\n",
    "        updated_content_str = json.dumps(content_dict)\n",
    "        result = Review.model_validate_json(updated_content_str)\n",
    "\n",
    "        if verbose:\n",
    "            print(user_msg)\n",
    "            print(f\"Eval: {result}\\n\")\n",
    "\n",
    "        return result\n",
    "    except JSONDecodeError as e:\n",
    "        print(e)\n",
    "\n",
    "chat = get_chat_completion()\n",
    "aligned = 0\n",
    "tot = 0\n",
    "for guid, score in ra._ReviewApp__reviews.items():\n",
    "    note = deck.get(guid=guid)[0]\n",
    "    pred = review_note(note, chat, verbose=True)\n",
    "    print(f\"Ground Truth: {score}\\n\")\n",
    "    if pred.is_correct == eval(score):\n",
    "        aligned += 1\n",
    "    tot += 1\n",
    "    print(\"#######################\\n\")\n",
    "\n",
    "print(f\"Alignment: {aligned}/{tot} ({aligned / tot:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345368e-26f6-4e5c-9e3e-fd2c08d7ba05",
   "metadata": {},
   "source": [
    "Some of the mistakes the LLM judge makes are due to:\n",
    "* Missing original note, which makes it hard to know if an `<img>` was removed\n",
    "* Reviewing the format of the tags (??)\n",
    "* Being lenient with not closing code block―which is technically valid markdown code, so maybe we could let it slide\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca9f553-afb1-4cf5-8ef8-a93e7ba53571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original note:\n",
      "Front: \"<img src=\"\"paste-bd59a972734fb91c3325b1dec38ea93d47925ab7.jpg\"\">\"\n",
      "Back: Locker\n",
      "Tags: ['english']\n",
      "New note:\n",
      "Front: Locker\n",
      "Back: Locker\n",
      "Tags: ['english']\n",
      "Eval: guid='A$U26>n14?' reasoning='The improved note is missing the image from the original note. It should preserve the image present on the original note.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: When talking about vocabulary size, what is the main difference between character-level and word-level tokenization?\n",
      "Back: \"Character-level tokenizers have much smaller vocabularies<br><br><div><img src=\"\"paste-ab8f01c4dc695a6f0d8fa93effdca0c77b94398d.jpg\"\"><br></div>\"\n",
      "Tags: ['nlp']\n",
      "New note:\n",
      "Front: Character-level vs word-level tokenization\n",
      "Back: Character-level tokenizers have much smaller vocabularies\n",
      "Tags: ['nlp']\n",
      "Eval: guid='\"c#*tMdp`:C\"' reasoning='The improved note is missing the image and the line breaks. The original note had a clear separation between the two lines of text, which is not present in the improved note. Also, the improved note does not use the hybrid markdown format properly.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is another name for the chipset PCIe lanes?\n",
      "Back: PCH lanes\n",
      "Tags: ['gpu', 'hardware']\n",
      "New note:\n",
      "Front: Chipset PCIe lanes name\n",
      "Back: PCH lanes\n",
      "Tags: ['gpu', 'hardware']\n",
      "Eval: guid='hVkGAdktL6' reasoning='The improved note is properly formatted. It uses a concise and clear title on the front, and the back still contains the same information as the original note. The tags are also preserved. However, the note does not require any special formatting as it does not include code, math equations, or long sentences. Therefore, the note is correctly formatted in a simple hybrid markdown format.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is the difference between WebSockets and traditional web communication methods like HTTP?\n",
      "Back: \"HTTP follows a request-response model. WebSockets introduce a full-duplex communication channel<br><br><img alt=\"\"What is WebSocket and How It Works?\"\" src=\"\"63fe48adb8834a29a618ce84_148.3.png\"\">\"\n",
      "Tags: ['system-design']\n",
      "New note:\n",
      "Front: WebSockets vs traditional web communication\n",
      "Back: HTTP follows a request-response model. WebSockets introduce a full-duplex communication channel\n",
      "Tags: ['system-design']\n",
      "Eval: guid='yyo348j{|9' reasoning='The improved note is missing the image and the formatting is not using hybrid markdown. The original note has an image and the back of the note is not properly formatted.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is Test Time Augumentation?\n",
      "Back: At inference or validation time, creating multiple versions of each image using data augmentation, and then taking the average or maximum of the predictions for each version of the image\n",
      "Tags: ['fastai']\n",
      "New note:\n",
      "Front: Test Time Augmentation\n",
      "Back: At inference/validation time, create multiple versions of each image using data augmentation, then take the average/max of predictions for each version.\n",
      "Tags: ['fastai']\n",
      "Eval: guid='N1O$1BYpt$' reasoning=\"The improved note is missing the proper formatting for the back of the card. It should use a hybrid markdown format to make the text more readable. The original note uses a period to separate the two main ideas, but the improved note does not. Additionally, the improved note does not use any special formatting for code or math equations, which is not necessary in this case, but it does not follow the original note's format either. However, the improved note does not preserve the original note's formatting, which is a requirement.\" is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is a left-handed golf stance?\n",
      "Back: \"<img src=\"\"paste-100bb3db40b4344e4101a08728f9602471adbf5f.png\"\">\"\n",
      "Tags: ['golf']\n",
      "New note:\n",
      "Front: Left-handed golf stance\n",
      "Back: Feet and knees aligned with target line, weight on left foot, clubface open 10-15 degrees\n",
      "Tags: ['golf']\n",
      "Eval: guid='MPiZ(&lAxK' reasoning=\"The improved note is missing the image from the original note. It should preserve the image present on the original note. Also, the original note's front was a question, while the improved note's front is a statement. However, since the content is the same, this is not a formatting issue.\" is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is Working Capital used for?\n",
      "Back: To gauge the short-term health of an organization\n",
      "Tags: ['finance']\n",
      "New note:\n",
      "Front: Working Capital use\n",
      "Back: To gauge the short-term health of an organization\n",
      "Tags: ['finance']\n",
      "Eval: guid='J1um1e@6EN' reasoning='The improved note is properly formatted. It uses the hybrid markdown format, preserves the original content, and maintains the same tags as the original note. However, the front of the note could be more descriptive, but it is not required for this note. The main issue is that the original note had a question on the front, which is now missing. However, since the question was not complex, the note is still understandable. The note is still True because the original note was not complex and the question was not complex, so the note is still understandable.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What keymap creates a new tab?\n",
      "Back: `t`\n",
      "Tags: ['vimium']\n",
      "New note:\n",
      "Front: New tab keymap\n",
      "Back: `t`\n",
      "Tags: ['vimium']\n",
      "Eval: guid='cAGU,We~`~' reasoning=\"The improved note is missing the key information about what keymap creates a new tab. The original note had 'What keymap creates a new tab?' on the front, which is a crucial piece of information. The improved note only has 'New tab keymap' which is not descriptive enough.\" is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: How can we add or increment a value in a `HashMap`?\n",
      "Back: ```rust<br>match map.get(&amp;w) {<br>&nbsp; &nbsp; Some(count) =&gt; { map.insert(w, count + 1); }<br>&nbsp; &nbsp; None =&gt; { map.insert(w, 1); }<br>}<br>```\n",
      "Tags: ['rust-lang']\n",
      "New note:\n",
      "Front: Increment HashMap value\n",
      "Back: ```rust<br>match map.get(&w) {<br>    Some(count) => { map.insert(w, count + 1); }<br>    None => { map.insert(w, 1); }<br>}\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='u,FyN]W/|%' reasoning='The improved note is missing the non-breaking space (&nbsp;) in the code block. It should be `&nbsp;` instead of just a space in the `match` statement. Also, the improved note is missing the `&` symbol in the `map.get(&w)` line, which is present in the original note.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What keymap opens all folds?\n",
      "Back: `zR` — Reduce folds (opens all folds)\n",
      "Tags: ['nvim']\n",
      "New note:\n",
      "Front: Open all folds\n",
      "Back: `zR` — Reduce folds (opens all folds)\n",
      "Tags: ['nvim']\n",
      "Eval: guid='\"fC+uI=1h#=\"' reasoning=\"The improved note is missing the question on the front side, which is a crucial part of the note. It should be 'What keymap opens all folds?' instead of just 'Open all folds'.\" is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: \"What happens to `s1` after we assign `s1` to `s2`?<br><br>```rust<br>let s1 = String::from(\"\"hello\"\");<br>let s2 = s1;<br>```\"\n",
      "Back: \"`s1` is invalidated.&nbsp;<br><br>```bash<br>&gt; cargo run<br>&nbsp;&nbsp; Compiling ownership v0.1.0 (file:///projects/ownership)<br>error[E0382]: borrow of moved value: `s1`<br> --&gt; src/main.rs:5:28<br>&nbsp; |<br>2 |&nbsp;&nbsp;&nbsp;&nbsp; let s1 = String::from(\"\"hello\"\");<br>&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait<br>3 |&nbsp;&nbsp;&nbsp;&nbsp; let s2 = s1;<br>&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- value moved here<br>4 |<br>5 |&nbsp;&nbsp;&nbsp;&nbsp; println!(\"\"{}, world!\"\", s1);<br>&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ^^ value borrowed here after move<br>&nbsp; |<br>&nbsp; = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info)<br>help: consider cloning the value if the performance cost is acceptable<br>&nbsp; |<br>3 |&nbsp;&nbsp;&nbsp;&nbsp; let s2 = s1.clone();<br>&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ++++++++<br><br>For more information about this error, try `rustc --explain E0382`.<br>error: could not compile `ownership` due to previous error<br>```\"\n",
      "Tags: ['rust-lang']\n",
      "New note:\n",
      "Front: Assign `s1` to `s2`\n",
      "Back: `s1` is invalidated. Consider using `s1.clone()` instead.\\n```bash\"> cargo run\"> Compiling ownership v0.1.0 (file:///projects/ownership)\"> error[E0382]: borrow of moved value: `s1`\">  --> src/main.rs:5:28\">  |\"> 2 |     let s1 = String::from(\"\"hello\"\");\">  |         -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait\"> 3 |     let s2 = s1;\">  |              -- value moved here\"> 4 |\"> 5 |     println!(\"\"{} world!\"\", s1);\">  |                            ^^ value borrowed here after move\">  |\">  = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info)\"> help: consider cloning the value if the performance cost is acceptable\">  |\"> 3 |     let s2 = s1.clone();\">  |                ++++++++\"> For more information about this error, try `rustc --explain E0382`.\"> error: could not compile `ownership` due to previous error\"> ```\n",
      "Tags: ['rust-lang']\n",
      "Eval: guid='sefDNl}8>v' reasoning='The improved note is missing the code block for the Rust code and the language specification. It also uses a backslash (`\") to signal a new line, which is not a standard way to do it in Anki. The original note uses a hybrid markdown format with `<br>` to signal a new line. The improved note also does not preserve the original formatting of the error message, which is a code block with a specific language (`bash`).' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What are the two main steps to process the raw text before passing it to a Transformer model?\n",
      "Back: <ol><li>Tokenization</li><li>Numericalization</li></ol>\n",
      "Tags: ['nlp']\n",
      "New note:\n",
      "Front: Text preprocessing for Transformer model\n",
      "Back: TokenizationNumericalization\n",
      "Tags: ['nlp']\n",
      "Eval: guid='D;FouTT/-X' reasoning='The improved note is missing the ordered list format, which was present in the original note. It should be preserved to maintain consistency and clarity.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: \"<span style=\"\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"\">The windshield is&nbsp;</span>{{c1::steaming up}}<div><span style=\"\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"\"><br></span></div><div><img src=\"\"paste-d40be9ff3ddb1f885b1eb5ffdc40528f6597bb4d.jpg\"\"><span style=\"\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"\"><br></span></div>\"\n",
      "Back: \n",
      "Tags: ['english']\n",
      "New note:\n",
      "Front: The windshield is steaming up\n",
      "Back: The windshield is fogging up due to high humidity or temperature difference.\n",
      "Tags: ['english']\n",
      "Eval: guid='\"g~#puI)*I%\"' reasoning=\"The improved note is missing the image and the original formatting of the front. The original note had a span tag and a div tag which were used for styling and layout. The improved note does not have these tags. Also, the original note had a line break after 'steaming up' which is not present in the improved note. The image is also missing from the improved note.\" is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is the command to print manual or get help for a command?\n",
      "Back: ```bash<br>$ man ...<br>```\n",
      "Tags: ['linux']\n",
      "New note:\n",
      "Front: Get command manual/help\n",
      "Back: ```bash<br>$ man <command><br>```\n",
      "Tags: ['linux']\n",
      "Eval: guid='s=l*N,i*FW' reasoning='The improved note is missing the ellipsis (...) in the code block, which is present in the original note. The original note has $ man ...$ which is a LaTeX block for a mathematical equation, but in this case, it seems to be used for a command. The improved note is missing the ellipsis in the code block, which is not properly formatted.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: $ \\frac{\\partial}{\\partial x} [f(x) - g(x)] = {{c1:: \\frac{\\partial}{\\partial x} f(x) -&nbsp;\\frac{\\partial}{\\partial x} g(x)&nbsp;}} $\n",
      "Back: Difference Rule\n",
      "Tags: ['math']\n",
      "New note:\n",
      "Front: $ \\\\[\\frac{\\partial}{\\partial x} [f(x) - g(x)] = {{c1:: \\frac{\\partial}{\\partial x} f(x) - \\frac{\\partial}{\\partial x} g(x) }} \\]$\n",
      "Back: Difference Rule\n",
      "Tags: ['math']\n",
      "Eval: guid='fqco;Q7@H~' reasoning='The improved note uses a LaTeX block to display the mathematical equation, which is correct. However, it incorrectly uses double backslashes, \\\\, in the LaTeX block. This will not be correctly displayed in Anki. The rest of the formatting seems to be correct, including the use of a code block for the formula and the preservation of the original tags.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is Brig's favorite food?\n",
      "Back: Sandwiches\n",
      "Tags: ['life']\n",
      "New note:\n",
      "Front: Brig's favorite food\n",
      "Back: Sandwiches\n",
      "Tags: ['life']\n",
      "Eval: guid='MaS+8AHK*6' reasoning='The improved note is missing the question mark at the end of the front, which is a crucial part of the question. The original note is properly formatted as a question, while the improved note is not.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: How is the formula to compute accuracy?\n",
      "Back: $&nbsp;\\text{ACC} = \\frac{ \\text{TP} + \\text{TN} }{ \\text{TP} + \\text{FP} + \\text{TN} + \\text{FN} } $\n",
      "Tags: ['classification', 'ml']\n",
      "New note:\n",
      "Front: Accuracy formula\n",
      "Back: $\\\\[math] \\\\[text{ACC} = \\frac{ \\text{TP} + \\text{TN} }{ \\text{TP} + \\text{FP} + \\text{TN} + \\text{FN} } \\[/math] $\n",
      "Tags: ['classification', 'ml']\n",
      "Eval: guid='bd[&6V7P?]' reasoning='The improved note uses double backslashes, \\\\\\\\, in the LaTeX block, which will not be correctly displayed. It also uses double backslashes, \\\\\\\\, in the LaTeX block, which is unnecessary and incorrect. The correct LaTeX block should be $[math] ... [/math].' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What does DJIA stand for?\n",
      "Back: Dow Jones Industrial Average&nbsp;\n",
      "Tags: ['finance']\n",
      "New note:\n",
      "Front: DJIA meaning\n",
      "Back: Dow Jones Industrial Average\n",
      "Tags: ['finance']\n",
      "Eval: guid='m%{1B{Q1jr' reasoning='The improved note is properly formatted. It uses a concise format, and the tags are preserved. However, the front of the note could be improved by using a question mark at the end, like the original note. But it still meets the basic requirements.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: In the Bayes Theorem, what is the common name for $ P(A | B) $?\n",
      "Back: \"The <b><font color=\"\"#ef2929\"\">posterior<br><br></font></b><img src=\"\"1CnoTGGO7XeUpUMeXDrIfvA.png\"\"><br>\"\n",
      "Tags: ['stats']\n",
      "New note:\n",
      "Front: Bayes Theorem conditional probability\n",
      "Back: The posterior\n",
      "Tags: ['stats']\n",
      "Eval: guid='JW|~i]cGSh' reasoning='The improved note does not preserve the image present on the original note. It also does not use the correct formatting for the posterior, which was originally in bold red color and had a line break.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What is another name for the Jaccard index?\n",
      "Back: Intersection over union\n",
      "Tags: ['ml']\n",
      "New note:\n",
      "Front: Jaccard index synonym\n",
      "Back: Intersection over union\n",
      "Tags: ['ml']\n",
      "Eval: guid='MrC556~`Pm' reasoning='The improved note is missing the front description and uses a more concise format. However, it does not use the hybrid markdown format as the original note. It does not use <br> to signal a new line, &nbsp; to signal a non-breaking space, &lt; for < symbol, etc. It also does not wrap code or math equations in the correct format.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What does SSL stand for?\n",
      "Back: Self-supervised learning\n",
      "Tags: ['ml']\n",
      "New note:\n",
      "Front: SSL meaning\n",
      "Back: Self-supervised learning\n",
      "Tags: ['ml']\n",
      "Eval: guid='pJ8P[<D3z&' reasoning='The improved note is properly formatted. It uses a concise format for the front and back of the note, and the tags are correctly formatted. There is no need for special formatting in this case, as the note only contains a single sentence without code or math equations.' is_correct=True\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: \"What is *document mimicry*?<br><br><img src=\"\"paste-0d3ce1da9a9e4c403fd9e49251d1519f497c9d28.jpg\"\">\"\n",
      "Back: \"A form of prompting which consists in trying to mimic as closely as possible the format of documents that the LLM saw during training (e.g., a conversation transcript)<br><br><img src=\"\"paste-e1560bf15b31f587a65e913a81ea949b211fdc09.jpg\"\">\"\n",
      "Tags: ['llm']\n",
      "New note:\n",
      "Front: Document mimicry\n",
      "Back: A form of prompting which consists in trying to mimic as closely as possible the format of documents that the LLM saw during training (e.g., a conversation transcript)\n",
      "Tags: ['llm']\n",
      "Eval: guid='x43Ud=[8]O' reasoning='The improved note is missing the images and the original formatting of the front side. The original note had a title in italics, which is not present in the improved note. The improved note is also missing the line breaks, which are present in the original note.' is_correct=False\n",
      "\n",
      "Ground Truth: True\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: When Presizing, how is the initial resizing done on the validation set?\n",
      "Back: The center square of the image is always chosen\n",
      "Tags: ['dl', 'fastai', 'ml']\n",
      "New note:\n",
      "Front: Presizing initial validation set resizing\n",
      "Back: The center square of the image is always chosen\n",
      "Tags: ['dl', 'fastai', 'ml']\n",
      "Eval: guid='AY+9%meG%9' reasoning='The improved note is missing the question mark at the end of the front side, which is a crucial part of a question.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What does `docker ps` stand for?\n",
      "Back: [p]rocess [s]tatus\n",
      "Tags: ['docker']\n",
      "New note:\n",
      "Front: Docker ps meaning\n",
      "Back: [p]rocess [s]tatus\n",
      "Tags: ['docker']\n",
      "Eval: guid='Mmzr]&:9e0' reasoning='The improved note is missing the question mark at the end of the front side, which is present in the original note. It also does not use the hybrid markdown format for the front side. The back side is properly formatted, but the front side is not.' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Original note:\n",
      "Front: What command opens an older quickfix list?\n",
      "Back: `:colder`\n",
      "Tags: ['nvim']\n",
      "New note:\n",
      "Front: Open older quickfix list\n",
      "Back: :colder\n",
      "Tags: ['nvim']\n",
      "Eval: guid='b~pDqG>Kbv' reasoning='The improved note is missing the formatting for the code block. It should be wrapped in a code block: `:colder<br>`' is_correct=False\n",
      "\n",
      "Ground Truth: False\n",
      "\n",
      "\n",
      "#######################\n",
      "\n",
      "Alignment: 15/25 (60.00%)\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MSG = r\"\"\"\n",
    "The user will share two Anki notes: the original and improved versions. The improved version should be factually the same as the original note but more concise and might have a slightly different format.\n",
    "\n",
    "Your job is to evaluate the formatting of the improved version. Properly formatted notes should:\n",
    "* Use hybrid markdown format. For instance, when relevant, use `<br>` to signal a new line, `&nbsp;` to signal a non-breaking space, `&lt;` for `<` symbol, etc. Cards with just one sentence that do not include code or math equations do not require special formatting\n",
    "* Preserve images and media present on the original note\n",
    "* Code should be wrapped in a code block: ```<language><br><command><br>```. One line command should use an inline code block: `iw`, `d`, `:copen`, etc.\n",
    "* Mathematical equations should be wrapped in a LaTeX block: $ <math equation> $. Also, ensure that we do not use double backslashes, \\\\, in a LaTeX block, as that won't be correctly displayed\n",
    "\n",
    "Provide concise reasoning for your answer and a True/False answer, where True means the improved note is formatted correctly and False means the improved note is not properly formatted.\n",
    "\"\"\"\n",
    "\n",
    "class Review(BaseModel):\n",
    "    guid: str\n",
    "    reasoning: str \n",
    "    is_correct: bool\n",
    "\n",
    "def review_note(note: Note, chat: ChatCompletionsService, verbose=False) -> Note:\n",
    "    orig = orig_deck.get(note.guid)[0]\n",
    "    user_msg = f\"\"\"Original note:\\nFront: {orig.front}\\nBack: {orig.back}\\nTags: {orig.tags}\\nNew note:\\nFront: {note.front}\\nBack: {note.back}\\nTags: {note.tags}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": user_msg},\n",
    "    ]\n",
    "    extra_body = {\n",
    "        \"guided_json\": Review.model_json_schema(),\n",
    "        \"guided_whitespace_pattern\": r\"[\\n\\t ]*\",\n",
    "    }\n",
    "\n",
    "    chat_response = chat.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        messages=messages,  # type: ignore\n",
    "        temperature=0,\n",
    "        extra_body=extra_body,\n",
    "    )\n",
    "    content_str: str = cast(str, chat_response.choices[0].message.content)\n",
    "    try:\n",
    "        content_dict = json.loads(content_str)\n",
    "        content_dict[\"guid\"] = note.guid\n",
    "        updated_content_str = json.dumps(content_dict)\n",
    "        result = Review.model_validate_json(updated_content_str)\n",
    "\n",
    "        if verbose:\n",
    "            print(user_msg)\n",
    "            print(f\"Eval: {result}\\n\")\n",
    "\n",
    "        return result\n",
    "    except JSONDecodeError as e:\n",
    "        print(e)\n",
    "\n",
    "chat = get_chat_completion()\n",
    "aligned = 0\n",
    "tot = 0\n",
    "for guid, score in ra._ReviewApp__reviews.items():\n",
    "    note = deck.get(guid=guid)[0]\n",
    "    pred = review_note(note, chat, verbose=True)\n",
    "    print(f\"Ground Truth: {score}\\n\")\n",
    "    if pred.is_correct == eval(score):\n",
    "        aligned += 1\n",
    "    tot += 1\n",
    "    print(\"#######################\\n\")\n",
    "\n",
    "print(f\"Alignment: {aligned}/{tot} ({aligned / tot:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a996d-da73-4f5e-bebe-40df05ddba56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d2bd8-c9ea-47c4-9a2b-9d4c14e6c93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631d493-4748-4c05-aed6-cd8bd3e0c092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0bb3b-79fe-4839-82b2-a88b42b89615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff80ce-6650-4912-8f87-fb78628fa084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530edab6-1006-44e6-ac1c-6ffadcab7095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "017974df-4813-447e-8b53-ee6fae73c622",
   "metadata": {},
   "source": [
    "### Create helper functions to facilitate reviewing notes\n",
    "\n",
    "Let's create a `pandas.DataFrame` with both: original note, edited note, and LLM review. This will facilitate our review of the LLM reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf1acc2-cd57-43bd-8eb5-ddc7751151b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dict_data \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mdict() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m]\n\u001b[1;32m      2\u001b[0m df_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dict_data)\n\u001b[1;32m      3\u001b[0m df_scores\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "dict_data = [item.dict() for item in results]\n",
    "df_scores = pd.DataFrame(dict_data)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f345c24-71b9-4b66-9851-a41df05a967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [note.dict() for note in deck]\n",
    "df_notes = pd.DataFrame(a)\n",
    "df_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe3d5f-5f7e-4004-a8be-0a041b18f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.merge(df_notes, df_scores, how=\"inner\", on=\"guid\")\n",
    "x = x[x.tags.apply(lambda a: \"life\" not in a)]  # exclude personal notes\n",
    "print(x.shape)\n",
    "x.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67017da-94d2-41bf-b141-3f59f5caddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_interactive_session(session_text):\n",
    "    lines = session_text.strip().split(\"<br>\")\n",
    "    input_pattern = r\"^>>> .*$\"\n",
    "    continuation_pattern = r\"^... .*$\"\n",
    "    output_pattern = r\"^(?!>>>)(?!\\.\\.\\.)\"\n",
    "\n",
    "    state = \"expecting_input\"\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        if state == \"expecting_input\":\n",
    "            if not (\n",
    "                re.match(input_pattern, line) or re.match(continuation_pattern, line)\n",
    "            ):\n",
    "                return False, f\"Line {i}: Expected input (>>> or ...), got: {line}\"\n",
    "            state = \"optional_output\"\n",
    "        elif state == \"optional_output\":\n",
    "            if re.match(input_pattern, line) or re.match(continuation_pattern, line):\n",
    "                state = \"expecting_input\"\n",
    "            elif not re.match(output_pattern, line):\n",
    "                return False, f\"Line {i}: Invalid output format: {line}\"\n",
    "\n",
    "    return True, \"Valid interactive session format\"\n",
    "\n",
    "\n",
    "def validate_code_block_format(block):\n",
    "    # Check if the block starts and ends with ```\n",
    "    if not (block.startswith(\"```\") and block.endswith(\"```\")):\n",
    "        return False, \"Code block should start and end with ```\"\n",
    "\n",
    "    # Remove the opening and closing ```\n",
    "    content = block[3:-3].strip()\n",
    "\n",
    "    # Check if the block starts with a language specifier\n",
    "    if not re.match(r\"^[\\w-]+<br>\", content):\n",
    "        return (\n",
    "            False,\n",
    "            \"Code block should start with a language specifier followed by <br>\",\n",
    "        )\n",
    "\n",
    "    # Split the content by <br> tags\n",
    "    lines = content.split(\"<br>\")\n",
    "\n",
    "    # Check if the last line is empty (as it should end with <br>)\n",
    "    if lines[-1].strip() != \"\":\n",
    "        return False, \"Code block should end with <br>\"\n",
    "\n",
    "    # Check if there are any empty lines in between (which would indicate missing <br>)\n",
    "    if any(line.strip() == \"\" for line in lines[1:-1]):\n",
    "        return (\n",
    "            False,\n",
    "            \"Code block should not have empty lines. Use <br> for line breaks.\",\n",
    "        )\n",
    "\n",
    "    return True, \"Valid code block format\"\n",
    "\n",
    "\n",
    "def validate_hybrid_markdown(content):\n",
    "    issues = []\n",
    "\n",
    "    # Check for double backslashes in LaTeX blocks\n",
    "    latex_blocks = re.findall(r\"\\$(.*?)\\$\", content, re.DOTALL)\n",
    "    for block in latex_blocks:\n",
    "        if \"\\\\\\\\\" in block:\n",
    "            issues.append(\n",
    "                \"Double backslash (\\\\\\\\) found in LaTeX block. This may cause rendering issues.\"\n",
    "            )\n",
    "\n",
    "    # Check for unmatched dollar signs\n",
    "    # Split the content into code blocks and non-code blocks\n",
    "    parts = re.split(r\"(```[\\s\\S]*?```)\", content)\n",
    "\n",
    "    total_dollar_count = 0\n",
    "    for part in parts:\n",
    "        if part.startswith(\"```\") and part.endswith(\"```\"):\n",
    "            # This is a code block\n",
    "            is_valid, message = validate_code_block_format(part)\n",
    "            if not is_valid:\n",
    "                issues.append(f\"Invalid code block format: {message}\")\n",
    "\n",
    "            if part.startswith(\"```python\"):\n",
    "                # Check if it's an interactive Python session\n",
    "                session_content = part[13:-3].strip()  # Remove ```python<br> and ```\n",
    "                is_valid, message = validate_interactive_session(session_content)\n",
    "                if not is_valid:\n",
    "                    issues.append(\n",
    "                        f\"Invalid Python interactive session in code block: {message}\"\n",
    "                    )\n",
    "        else:\n",
    "            # Count dollar signs in non-code block parts\n",
    "            dollar_count = part.count(\"$\")\n",
    "            total_dollar_count += dollar_count\n",
    "\n",
    "    # Check if the total number of dollar signs outside code blocks is odd\n",
    "    if total_dollar_count % 2 != 0:\n",
    "        issues.append(\n",
    "            \"Unmatched dollar signs outside code blocks. LaTeX may not render correctly.\"\n",
    "        )\n",
    "\n",
    "    # Check for common Markdown syntax errors\n",
    "    if \"```\" in content and content.count(\"```\") % 2 != 0:\n",
    "        issues.append(\n",
    "            \"Unmatched code block delimiters (```). Code blocks may not render correctly.\"\n",
    "        )\n",
    "\n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de65941-7107-4a17-88cc-3590d0f1ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reviews = 100\n",
    "\n",
    "for row in x.iloc[:n_reviews].iterrows():\n",
    "    note = row[1]\n",
    "    print(f\"Front: {note['front']}\\nBack: {note['back']}\\nTags: {note['tags']}\")\n",
    "    for side in [\"front\", \"back\"]:\n",
    "        a = note[side]\n",
    "        issues = validate_hybrid_markdown(a)\n",
    "        if issues:\n",
    "            for issue in issues:\n",
    "                print(f\"Issue {side}: {issue}\")\n",
    "        else:\n",
    "            print(f\"Issue {side}: None\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9168c-46f6-49a7-851b-4b23a9669aff",
   "metadata": {},
   "source": [
    "Common errors are:\n",
    "\n",
    "* Missing `<img>`\n",
    "* Wrong prompt (e.g., `>>`, missing `$`)\n",
    "* Missing `<br>` inside code block\n",
    "* Missing `<br>` outside code block\n",
    "* `\\\\` in LaTeX\n",
    "* References (should we remove them?)\n",
    "* Trailing `.` (full stop)\n",
    "* Using code block for note that does not contain code\n",
    "* \"```bash\" for keymap\n",
    "* Missing language in code block\n",
    "* Unmatched code block delimiter (missing trailing \"```\")\n",
    "* Missing inline code block for keymap or short commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fc84d-92e4-4f4a-a84f-cd96d9921e5b",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "- [ ] Create a dataset to measure LLM judge's alignment with human preference \n",
    "- [ ] Use _reflection_ agentic workflow to improve notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096944a4-fb5c-47b1-ac86-88ac99949927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
