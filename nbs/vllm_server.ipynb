{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad251cb3-a145-4cd6-9501-81fd4041f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd1bbcb-16f8-4494-b4a0-73766a6e3a9b",
   "metadata": {},
   "source": [
    "Please run the following command on the terminal to spin up a vLLM server, which we will query in the rest of the notebook.\n",
    "\n",
    "\n",
    "```bash\n",
    "vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --max_model_len 4096 --chat-template ./template_llama31.jinja\n",
    "```\n",
    "\n",
    "We might have to wait about 1 minute before the server is up and reachable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87845dae-ed20-4a70-9a14-4dc11067b93b",
   "metadata": {},
   "source": [
    "### Using OpenAI Completions API with vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5610db-8bc5-40f6-9a2f-8aeb53f99808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"cmpl-c6ab3ebe1b50409fbde408d32c884899\",\"object\":\"text_completion\",\"created\":1725109226,\"model\":\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\"choices\":[{\"index\":0,\"text\":\" top tourist destination, and for good\",\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null,\"prompt_logprobs\":null}],\"usage\":{\"prompt_tokens\":5,\"total_tokens\":12,\"completion_tokens\":7}}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8000/v1/completions -H \"Content-Type: application/json\" -d '{     \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",   \"prompt\": \"San Francisco is a\",   \"max_tokens\": 7,  \"temperature\": 0 }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd20c7e-c0b4-44c3-bd7b-3153a287e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519849d8-b628-4762-a0db-fb26dab253f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18f0160-ed90-4ba0-b586-be72ff439142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion result:  top tourist destination, and for good\n"
     ]
    }
   ],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    prompt=\"San Francisco is a\",\n",
    "    temperature=0,\n",
    "    max_tokens=7,\n",
    ")\n",
    "print(\"Completion result:\", completion.choices[0].text);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bb08d-8661-4e51-9c78-8b3d200fa66c",
   "metadata": {},
   "source": [
    "### Using OpenAI Chat API with vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cc64cd-3402-4786-ae08-c70dba342f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: The result of 2 + 2 is 4.\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the result of 2 + 2?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(\"Chat response:\", chat_response.choices[0].message.content);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4da63-66bd-46a4-a6cf-18d2f7c05298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
