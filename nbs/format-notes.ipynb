{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3eefeb-4844-42a6-b03e-c4af38dafb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from anki_ai.domain.model import Deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336ace9c-f427-416c-b9ae-00460321e63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a1d40-c98c-4d90-8456-3679f2890018",
   "metadata": {},
   "source": [
    "When exporting notes from Anki, select the following options:\n",
    "- Notes in plain text (.txt)\n",
    "- Include HTML and media references\n",
    "- Include tags\n",
    "- Include deck name\n",
    "- Include notetype name\n",
    "- Include unique identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d988d3d1-84bc-4029-baf2-2d6280abdc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The deck contains 2241 notes\n"
     ]
    }
   ],
   "source": [
    "deck = Deck(\"default\")\n",
    "deck.read_txt(\"../data/Selected Notes.txt\")\n",
    "print(f\"The deck contains {len(deck)} notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7d8c3-fe58-4324-bdb7-963b98e26246",
   "metadata": {},
   "source": [
    "One issue we need to handle is that our notes contain HTML and media reference, which can confuse the LLM when editing the note. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8487d266-27c3-440e-82a7-3b2aa2379f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```bash<br>$ ln -s &lt;file_name&gt; &lt;link_name&gt;<br>```'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deck[0].back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb6607d-8493-4955-993e-0b4c7d7bbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.text = StringIO()\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "\n",
    "def replace_br_with_newline(html_string):\n",
    "    import re\n",
    "\n",
    "    return re.sub(r\"<br\\s*/?>\", \"\\n\", html_string)\n",
    "\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(replace_br_with_newline(html))\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86233369-9aff-4a29-8ced-a440c0ea5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original note:\n",
      "```bash<br>$ ln -s &lt;file_name&gt; &lt;link_name&gt;<br>```\n",
      "\n",
      "Fixed:\n",
      "```bash\n",
      "$ ln -s <file_name> <link_name>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "back_card = deck[0].back\n",
    "print(f\"Original note:\\n{back_card}\\n\")\n",
    "print(f\"Fixed:\\n{strip_tags(back_card)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d6d6b9-3682-4599-ab8f-2d3f4d9f4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"microsoft/Phi-3-medium-4k-instruct\"\n",
    "# model_id = \"microsoft/Phi-3-small-8k-instruct\"\n",
    "# model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# model_id =\"Qwen/Qwen2-7BInstruct\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84468c8-6ceb-4f6a-af9c-7fa50d6cbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174d8940-9dde-440b-9c47-5f2bdffc0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_msg = \"\"\"You are an expert in building Anki cards.\n",
    "\n",
    "# The user will share an existing Anki note with you. Your job is to edit it to be more concise, simple, straightforward, and distinct.\n",
    "\n",
    "# Do not describe the changes you made. Reply in this format:\n",
    "\n",
    "# Front: [front section of card 1]\n",
    "# Back: [back section of card 1]\n",
    "\n",
    "# When providing commands to be executed in a terminal, please prefix each command with the $ symbol. This helps distinguish executable commands from output or other text. For example:\n",
    "# $ ls -l\n",
    "# $ cd /path/to/directory\n",
    "# $ python script.py\"\n",
    "\n",
    "# Note that the $ symbol represents the command prompt and should not be typed when actually executing the commands.\n",
    "# \"\"\"\n",
    "\n",
    "# for i in range(10):\n",
    "#     user_msg = f\"\"\"Front: {deck[i].front}\n",
    "#     Back: {deck[i].back}\n",
    "#     \"\"\"\n",
    "\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": system_msg},\n",
    "#         {\"role\": \"user\", \"content\": user_msg},\n",
    "#     ]\n",
    "\n",
    "#     tokenized_chat = tokenizer.apply_chat_template(\n",
    "#         messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "#     )\n",
    "#     new_tokens = model.generate(tokenized_chat, max_new_tokens=150)\n",
    "#     gen_text = tokenizer.batch_decode(\n",
    "#         new_tokens[:, tokenized_chat.shape[1] :], skip_special_tokens=True\n",
    "#     )[0]\n",
    "\n",
    "#     print(\"#######################\")\n",
    "#     print(f\"Front: {deck[i].front}\\nBack: {deck[i].back}\")\n",
    "#     print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96d20e-da3e-4ad0-b91f-5e1a6eabf002",
   "metadata": {},
   "source": [
    "### Using vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71d77e0-afae-42fe-a6f9-0307e6d8add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f904e8ee-47c0-4571-b0da-0ed37985c0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-27 22:26:31 llm_engine.py:184] Initializing an LLM engine (v0.5.5) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 08-27 22:26:32 model_runner.py:879] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 08-27 22:26:33 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b98a5c86874f349dc521230a74f15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-27 22:26:37 model_runner.py:890] Loading model weights took 14.9888 GB\n",
      "INFO 08-27 22:26:38 gpu_executor.py:121] # GPU blocks: 2398, # CPU blocks: 2048\n",
      "INFO 08-27 22:26:39 model_runner.py:1181] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 08-27 22:26:39 model_runner.py:1185] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 08-27 22:26:54 model_runner.py:1300] Graph capturing finished in 14 secs.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=model_id,\n",
    "    enable_prefix_caching=False,\n",
    "    gpu_memory_utilization=0.90,\n",
    "    max_model_len=4096,\n",
    "    # cpu_offload_gb=10,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74e675a7-4db8-4632-902d-b838d7bbb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(system_msg):\n",
    "    for i in range(10):\n",
    "        user_msg = f\"\"\"Front: {deck[i].front}\n",
    "        Back: {strip_tags(deck[i].back)}\n",
    "        \"\"\"\n",
    "\n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_msg,\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ]\n",
    "        outputs = llm.chat(\n",
    "            conversation, sampling_params=sampling_params, use_tqdm=False\n",
    "        )\n",
    "\n",
    "        print(\"#######################\")\n",
    "        print(f\"Front: {deck[i].front}\\nBack: {strip_tags(deck[i].back)}\")\n",
    "        print(outputs[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2388ae87-b3e2-4a36-84a8-f87f3889c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "Front: What command does create a soft link?\n",
      "Back: ```bash\n",
      "$ ln -s <file_name> <link_name>\n",
      "```\n",
      "Front: Create a soft link\n",
      "Back: ```bash\n",
      "$ ln -s\n",
      "#######################\n",
      "Front: In the `ln -s` command, what is the order of file name and link name?\n",
      "Back: ```bash\n",
      "$ ln -s <file_name> <link_name>\n",
      "```\n",
      "Front: ln -s command order of arguments\n",
      "Back: <file> then\n",
      "#######################\n",
      "Front: What command does extract files from a zip archive?\n",
      "Back: ```bash\n",
      "$ unzip <file>\n",
      "```\n",
      "Front: Extract files from zip archive\n",
      "Back: ```bash\n",
      "$ unzip <\n",
      "#######################\n",
      "Front: What is the command to list the content of a directory?\n",
      "Back: ```bash\n",
      "$ ls <path>\n",
      "```\n",
      "Front: List directory content\n",
      "Back: ```bash\n",
      "$ ls <path>\n",
      "\n",
      "#######################\n",
      "Front: What is the command to print text to the terminal window?\n",
      "Back: ```bash\n",
      "$ echo ...\n",
      "```\n",
      "Front: Print text to terminal\n",
      "Back: ```bash\n",
      "$ echo ...\n",
      "```\n",
      "#######################\n",
      "Front: What is the command to create a new file?\n",
      "Back: ```bash\n",
      "$ touch ...\n",
      "```\n",
      "Front: Create a new file\n",
      "Back: ```bash\n",
      "$ touch <filename\n",
      "#######################\n",
      "Front: What is the command to create a new directory?\n",
      "Back: ```bash\n",
      "mkdir ...\n",
      "```\n",
      "Front: Create a new directory\n",
      "Back: ```bash\n",
      "$ mkdir ...\n",
      "```\n",
      "#######################\n",
      "Front: What is the command to search text for patterns?\n",
      "Back: ```bash\n",
      "$ grep ...\n",
      "```\n",
      "Front: Search text for patterns\n",
      "Back: ```bash\n",
      "$ grep ...\n",
      "```\n",
      "#######################\n",
      "Front: What is the command to print manual or get help for a command?\n",
      "Back: ```bash\n",
      "$ man ...\n",
      "```\n",
      "Front: Print manual or get help for a command\n",
      "Back: ```bash\n",
      "\n",
      "#######################\n",
      "Front: What is the command to print the current working directory?\n",
      "Back: ```bash\n",
      "$ pwd \n",
      "```\n",
      "Front: Print current working directory\n",
      "Back: ```bash\n",
      "$ pwd\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "system_msg = \"\"\"\n",
    "Edit this Anki card:\n",
    "- Make it concise, simple, distinct\n",
    "- Follow formatting rules\n",
    "\n",
    "Front: [edited front]\n",
    "Back: [edited back]\n",
    "\n",
    "Terminal commands:\n",
    "```bash\n",
    "$ command here\n",
    "```\n",
    "\n",
    "Code:\n",
    "```language\n",
    "code here\n",
    "```\n",
    "\n",
    "No explanations.\n",
    "\n",
    "Example 1:\n",
    "Front: What command does extract files from a zip archive?\n",
    "Back: ```bash\n",
    "$ unzip <file>\n",
    "```\n",
    "Front: Extract files from zip archive\n",
    "Back: ```bash\n",
    "$ unzip <file>\n",
    "\n",
    "Example 2:\n",
    "Front: What is the command to print manual or get help for a command?\n",
    "Back: ```bash\n",
    "$ man ...\n",
    "```\n",
    "Front: Print manual or get help for a command\n",
    "Back: ```bash\n",
    "$ man ...\n",
    "```\n",
    "\n",
    "Example 3: \n",
    "Front: What command does create a soft link?\n",
    "Back: ```bash\n",
    "$ ln -s <file_name> <link_name>\n",
    "```\n",
    "Front: Create a soft link\n",
    "Back: \n",
    "```bash\n",
    "$ ln -s <file> <link>\n",
    "```\n",
    "\n",
    "Example 4:\n",
    "Front: In the `ln -s` command, what is the order of file name and link name?\n",
    "Back: ```bash\n",
    "$ ln -s <file_name> <link_name>\n",
    "```\n",
    "Front: ln -s command order of arguments\n",
    "Back: <file> then <link>\n",
    "\"\"\"\n",
    "\n",
    "generate(system_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03bb2dc8-cd3f-43d8-b501-2e5a8343efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "Front: What command does create a soft link?\n",
      "Back: ```bash\n",
      "$ ln -s <file_name> <link_name>\n",
      "```\n",
      "Front: What command does create a soft link?\n",
      "Back: ```bash\n",
      "$\n",
      "#######################\n",
      "Front: In the `ln -s` command, what is the order of file name and link name?\n",
      "Back: ```bash\n",
      "$ ln -s <file_name> <link_name>\n",
      "```\n",
      "Front: `ln -s` argument order\n",
      "Back: <file> then\n",
      "#######################\n",
      "Front: What command does extract files from a zip archive?\n",
      "Back: ```bash\n",
      "$ unzip <file>\n",
      "```\n",
      "Front: Extract files from a zip archive\n",
      "Back: ```bash\n",
      "$ unzip\n",
      "#######################\n",
      "Front: What is the command to list the content of a directory?\n",
      "Back: ```bash\n",
      "$ ls <path>\n",
      "```\n",
      "Front: List directory contents\n",
      "Back: ```bash\n",
      "$ ls <path>\n",
      "\n",
      "#######################\n",
      "Front: What is the command to print text to the terminal window?\n",
      "Back: ```bash\n",
      "$ echo ...\n",
      "```\n",
      "Front: Print text to the terminal\n",
      "Back: ```bash\n",
      "$ echo <\n",
      "#######################\n",
      "Front: What is the command to create a new file?\n",
      "Back: ```bash\n",
      "$ touch ...\n",
      "```\n",
      "Front: Create a new file\n",
      "Back: ```bash\n",
      "$ touch <file\n",
      "#######################\n",
      "Front: What is the command to create a new directory?\n",
      "Back: ```bash\n",
      "mkdir ...\n",
      "```\n",
      "Front: Create new directory\n",
      "Back: ```bash\n",
      "$ mkdir <path>\n",
      "\n",
      "#######################\n",
      "Front: What is the command to search text for patterns?\n",
      "Back: ```bash\n",
      "$ grep ...\n",
      "```\n",
      "Front: Pattern search in file\n",
      "Back: ```bash\n",
      "$ grep <pattern\n",
      "#######################\n",
      "Front: What is the command to print manual or get help for a command?\n",
      "Back: ```bash\n",
      "$ man ...\n",
      "```\n",
      "Front: `man` command syntax\n",
      "Back: ```bash\n",
      "$ man <\n",
      "#######################\n",
      "Front: What is the command to print the current working directory?\n",
      "Back: ```bash\n",
      "$ pwd \n",
      "```\n",
      "Front: Print current directory\n",
      "Back: ```bash\n",
      "$ pwd\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "system_msg = \"\"\"\n",
    "Optimize Anki cards:\n",
    "- Concise, simple, distinct\n",
    "- Follow format rules\n",
    "\n",
    "Reply in this format:\n",
    "Front: [edited front]\n",
    "Back: [edited back]\n",
    "\n",
    "Terminal commands:\n",
    "```bash\n",
    "$ command <placeholder>\n",
    "```\n",
    "\n",
    "Code:\n",
    "```language\n",
    "code here\n",
    "```\n",
    "\n",
    "Use the following placeholders only: <file>, <path>, <link>, <command>.\n",
    "\n",
    "No explanations.\n",
    "\n",
    "Examples:\n",
    "1. Front: Extract zip files\n",
    "   Back: ```bash\n",
    "   $ unzip <file>\n",
    "   ```\n",
    "\n",
    "2. Front: Get command manual/help\n",
    "   Back: ```bash\n",
    "   $ man <command>\n",
    "   ```\n",
    "\n",
    "3. Front: Create soft link\n",
    "   Back: ```bash\n",
    "   $ ln -s <file> <link>\n",
    "   ```\n",
    "\n",
    "4. Front: `ln -s` argument order\n",
    "   Back: <file> then <link>\n",
    "\"\"\"\n",
    "\n",
    "generate(system_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05748e-efdb-49c7-a75d-ff8b4c0998c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
